{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0b1515-e25f-4707-a240-b5c26d5d33f8",
   "metadata": {},
   "source": [
    "# ExamplerRunner Demo\n",
    "\n",
    "Run a chain on multiple examples for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fbc962-98e0-470c-9467-c5e28db658a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"http://127.0.0.1:8000\" \n",
    "\n",
    "import langchain\n",
    "from langchain.agents import Tool, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.evaluation.example_runner import ExampleRunner, CsvDataset\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afb6529-dfdb-4f0a-b19f-a700d80d4362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the dataset (only need to do once)\n",
    "runner = ExampleRunner(\n",
    "    csv_dataset=CsvDataset(\n",
    "        csv_path=\"test_dataset.csv\",\n",
    "        description=\"Dummy dataset for testing\",\n",
    "        input_keys=[\"input1\", \"input2\", \"input3\"],\n",
    "        output_keys=[\"output1\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603dc948-0a57-4696-8816-008aaf346538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(created_at=datetime.datetime(2023, 2, 9, 7, 45, 27, 878780), inputs={'input1': 'one', 'input2': ' two', 'input3': ' three'}, outputs={'output1': ' four'}, dataset_id=1, id=1),\n",
       " Example(created_at=datetime.datetime(2023, 2, 9, 7, 45, 27, 878790), inputs={'input1': 'five', 'input2': ' six', 'input3': ' seven'}, outputs={'output1': ' eight'}, dataset_id=1, id=2),\n",
       " Example(created_at=datetime.datetime(2023, 2, 9, 7, 45, 27, 878792), inputs={'input1': 'nine', 'input2': ' ten', 'input3': ' eleven'}, outputs={'output1': ' twelve'}, dataset_id=1, id=3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.dataset.examples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eba157-ec8e-43e9-8326-75099c07e574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  four\n",
      "\n",
      "Five\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Twelve\n",
      "\n",
      "\n",
      "Sixteen, seventeen, eighteen.\n",
      ",  twenty\n",
      "\n",
      "Twenty-one\n",
      "\n",
      "\n",
      "twenty-four\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  twenty-eight\n",
      "\n",
      "Twenty-nine\n",
      "\n",
      "\n",
      "Thirty-two.\n",
      "\n",
      "\n",
      "Thirty-six\n",
      ",  forty\n",
      "\n",
      "forty-one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Forty-four\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Forty-eight\n",
      "four\n",
      " eight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " twelve\n",
      " sixteen\n",
      "\n",
      "twenty\n",
      " twenty-four\n",
      " twenty-eight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " thirty-two\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.BaseOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " thirty-six\n",
      " forty\n",
      " forty-four\n",
      " forty-eight\n"
     ]
    }
   ],
   "source": [
    "runner = ExampleRunner(\n",
    "    langchain_dataset_name=\"test_dataset.csv\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"input1\", \"input2\", \"input3\"],\n",
    "    template=\"Complete the sequence: {input1}, {input2}, {input3}\",\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"input1\", \"input2\", \"input3\"],\n",
    "    template=\"\"\"\n",
    "    You are given the text representation of three numbers. You are to give the next number in the sequence. Only provide one number! \n",
    "    \n",
    "    Example:\n",
    "    Input: one, two three. \n",
    "    Output: four \n",
    "    \n",
    "    Input: {input1}, {input2}, {input3}\n",
    "    Output:\n",
    "    \"\"\"\n",
    ")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "runner.run_chain(chain1)\n",
    "runner.run_chain(chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510335a-872f-4392-829d-bdcba3a052cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
