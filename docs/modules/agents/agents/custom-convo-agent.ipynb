{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f8741",
   "metadata": {},
   "source": [
    "# Custom LLLM Agent\n",
    "\n",
    "This notebook goes through how to create your own custom LLM agent.\n",
    "\n",
    "An LLM agent consists of three parts:\n",
    "    \n",
    "    - Tools: The tools the agent has available to use.\n",
    "    - LLMChain: The LLMChain that produces the text that is parsed in a certain way to determine which action to take.\n",
    "    - OutputParser: This determines how to parse the LLMOutput into \n",
    "        \n",
    "        \n",
    "In this notebook we walk through how to create a custom LLM agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fc5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../../lang-chat/backend/\")\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3335ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.toolkits.open_api.toolkit import OpenAPIToolkit\n",
    "urls = [\n",
    "    \"https://www.klarna.com/.well-known/ai-plugin.json\"\n",
    "]\n",
    "def get_toolkits(urls):\n",
    "    return list(map(OpenAPIToolkit.from_plugin_url, urls))\n",
    "toolkits = get_toolkits(urls)\n",
    "namespaces = \"\\n\\n\".join([tk.get_typescript_namespace() for tk in toolkits])\n",
    "#print(namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor\n",
    "from langchain.agents.agent import LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339b1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following questions as best you can. You have access to the following tools (but you do not need to use them):\n",
    "\n",
    "{tools}\n",
    "\n",
    "If you want use a tool you should write valid TypeScript code to call it. Please put all parameters and their values on their own line. If you use strings, they should be wrapped in double quotes not single. Any arguments to this function should be values that can be loaded as json.\n",
    "\n",
    "For your response, you have two options:\n",
    "\n",
    "If you do not need to use any tools, you can just respond directly to the user by using the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Final Answer: your response to user here\n",
    "\n",
    "If you do need to use tools, you should use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: ```typescript\n",
    "...\n",
    "``` \n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question.\n",
    "\n",
    "When repsonding in your final answer to the user, they have NO knowledge of any intermediate steps. So if there is any intermediate knowledge there you want them to know, you should make sure to return it as part of your final answer.\n",
    "\n",
    "Remember, you do not need to use tools. For example, if the user asks a question that you KNOW the answer to, you can respond. If they ask a question that you do not know the answer to, but no tool can help, you should respond asking for clarification.\n",
    "\n",
    "Previous conversation (the question could be a follow up to something here):\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9274badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopify = toolkits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd969d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        kwargs = self._merge_partial_and_user_variables(**kwargs)\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        return template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc9de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_template = \"\"\"\\n\\nHuman: Answer the following questions as best you can. You have access to the following tools (but you do not need to use them):\n",
    "\n",
    "{tools}\n",
    "\n",
    "If you want use a tool you should write valid TypeScript code to call it. Please put all parameters and their values on their own line. If you use strings, they should be wrapped in double quotes not single. Any arguments to this function should be values that can be loaded as json.\n",
    "\n",
    "For your response, you have two options:\n",
    "\n",
    "If you do not need to use any tools, you can just respond directly to the user by using the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Final Answer: your response to user here\n",
    "\n",
    "If you do need to use tools, you should use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: ```typescript\n",
    "...\n",
    "``` \n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question.\n",
    "\n",
    "When repsonding in your final answer to the user, they have NO knowledge of any intermediate steps. So if there is any intermediate knowledge there you want them to know, you should make sure to return it as part of your final answer.\n",
    "\n",
    "Remember, you do not need to use tools. For example, if the user asks a question that you KNOW the answer to, you can respond. If they ask a question that you do not know the answer to, but no tool can help, you should respond asking for clarification.\n",
    "\n",
    "Previous conversation (the question could be a follow up to something here):\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\\n\\nAssistant: Thought:{agent_scratchpad}\"\"\"\n",
    "anthropic_template1 = \"\"\"{chat_history}\\n\\nHuman: \"You are a helpful assistant. A very smart language model.\n",
    "\n",
    "You have access to the following tools. The tools are TypeScript functions.\n",
    "\n",
    "{tools}\n",
    "\n",
    "If you want use a tool you should write valid TypeScript code to call it, always saving the output to a const with name \"langchain\". You should only make one function call at a time. Any arguments to this function should be values that can be loaded as json - e.g. no infinity values, etc. Any fuction calls MUST abide by the typescript definitions listed above.\n",
    "\n",
    "Return a helpful response to the user. If you need to call a tool to get more information, just write the code for the tool in between a [TOOL_USE_BEGIN] and [TOOL_USE_END] token markers. You will get a response from the tool in between a [TOOL_RESULT_BEGIN] and [TOOL_RESULT_END] tokens. \n",
    "The user you are are interacting with will not see the Tool invocation or the Tool repsonse. Therefor, if there is information there that answers their question, you must relay that information to the user.\n",
    "\n",
    "An example interaction may look like:\n",
    "\n",
    "<Begin Example>\n",
    "Human: What's the weather today?\n",
    "Assistant: [TOOL_USE_BEGIN]const langchain = weather.onDate({{query: \"1/2/2021\"}})[TOOL_USE_END][TOOL_RESULT_BEGIN]49 degrees[TOOL_RESULT_END]The weather today is 49 degrees.\n",
    "<End Example>\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\\n\\nAssistant:{agent_scratchpad}\"\"\"\n",
    "class CustomAnthropicPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        kwargs = self._merge_partial_and_user_variables(**kwargs)\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"[TOOL_USE_END][TOOL_RESULT_BEGIN]{observation}[TOOL_RESULT_END]\"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        return anthropic_template1.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5abf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_prompt = CustomAnthropicPromptTemplate(input_variables=[\"input\", \"intermediate_steps\", \"chat_history\", \"tools\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798ef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(input_variables=[\"input\", \"intermediate_steps\", \"chat_history\", \"tools\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74e3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\"\"\"\n",
    "\n",
    "\n",
    "SUFFIX = \"\"\"TOOLS\n",
    "------\n",
    "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
    "\n",
    "{tools}\n",
    "\n",
    "RESPONSE FORMAT INSTRUCTIONS\n",
    "----------------------------\n",
    "\n",
    "When responding to me please, please output a response in one of two formats:\n",
    "\n",
    "**Option 1:**\n",
    "Use this if you want the human to use a tool. Output should be in a typescript Markdown snippet.\n",
    "If you want use a tool you should write valid TypeScript code to call it. Please put all parameters and their values on their own line. If you use strings, they should be wrapped in double quotes not single. Any arguments to this function should be values that can be loaded as json.\n",
    "\n",
    "\n",
    "```typescript\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "**Option #2:**\n",
    "Use this if you want to respond directly to the human. Normal text formatted in the following schema:\n",
    "\n",
    "Final Answer:\n",
    "\n",
    "USER'S INPUT\n",
    "--------------------\n",
    "Here is the user's input (remember to respond as instructed):\n",
    "\n",
    "{input}\"\"\"\n",
    "\n",
    "TEMPLATE_TOOL_RESPONSE = \"\"\"TOOL RESPONSE: \n",
    "---------------------\n",
    "{observation}\n",
    "\n",
    "USER'S INPUT\n",
    "--------------------\n",
    "\n",
    "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond as instructed originally.\"\"\"\n",
    "import json\n",
    "from typing import Any, List, Optional, Sequence, Tuple\n",
    "\n",
    "from langchain.agents.agent import Agent\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.base import BasePromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptValue\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AgentAction,\n",
    "    AIMessage,\n",
    "    BaseLanguageModel,\n",
    "    BaseMessage,\n",
    "    BaseOutputParser,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    PromptValue,\n",
    ")\n",
    "from langchain.tools.base import BaseTool\n",
    "\n",
    "class CustomChatPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs: Any) -> str:\n",
    "        return self.format_prompt(**kwargs).to_string()\n",
    "    \n",
    "    def format_prompt(self, **kwargs: Any) -> PromptValue:\n",
    "        kwargs = self._merge_partial_and_user_variables(**kwargs)\n",
    "        result = [SystemMessage(content=PREFIX)] + kwargs[\"chat_history\"]\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        result.append(HumanMessage(content=SUFFIX.format(**kwargs)))\n",
    "        for action, observation in intermediate_steps:\n",
    "            result.append(AIMessage(content=action.log))\n",
    "            human_message = HumanMessage(\n",
    "                content=TEMPLATE_TOOL_RESPONSE.format(observation=observation)\n",
    "            )\n",
    "            result.append(human_message)\n",
    "        return ChatPromptValue(messages=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610bcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CHAT_TEMPLATE = CustomChatPromptTemplate(input_variables=[\"chat_history\", \"intermediate_steps\", \"input\", \"tools\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6fe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_ANSWER_ACTION = \"Final Answer:\"\n",
    "import json\n",
    "import json5\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output):\n",
    "        if FINAL_ANSWER_ACTION in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(FINAL_ANSWER_ACTION)[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        parsed = llm_output.split(\"Action:\")[1].split(\"```typescript\")[1].split(\"```\")[0].strip()\n",
    "        if parsed.startswith(\"const\"):\n",
    "            parsed = parsed.split(\" = \")[1]\n",
    "        typescript_str = parsed.split(\"(\")[1].split(\")\")[0]\n",
    "        tool_input = json.dumps(json5.loads(typescript_str))\n",
    "        return AgentAction(tool=parsed.split(\"(\")[0], tool_input=tool_input, log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d278706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdaa5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser1(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output):\n",
    "        if \"[TOOL_USE_BEGIN]\" not in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        parsed = llm_output.split(\"[TOOL_USE_BEGIN]\")[1].strip()\n",
    "        if parsed.startswith(\"const\"):\n",
    "            parsed = parsed.split(\" = \")[1]\n",
    "        typescript_str = parsed.split(\"(\")[1].split(\")\")[0]\n",
    "        tool_input = json.dumps(json5.loads(typescript_str))\n",
    "        return AgentAction(tool=parsed.split(\"(\")[0], tool_input=tool_input, log=llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf0aaf",
   "metadata": {},
   "source": [
    "## Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92186091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "def get_agent(toolkits, llm):\n",
    "    if isinstance(llm, OpenAI):\n",
    "        prompt_to_use = prompt.partial(tools=\"\\n\\n\".join([tk.get_typescript_namespace() for tk in toolkits]))\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", )\n",
    "        stop=[\"\\nObservation:\"]\n",
    "        output_parser = CustomOutputParser()\n",
    "    elif isinstance(llm, Anthropic):\n",
    "        prompt_to_use = anthropic_prompt.partial(tools=\"\\n\\n\".join([tk.get_typescript_namespace() for tk in toolkits]))\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", )\n",
    "        stop=[\"[TOOL_USE_END]\"]\n",
    "        output_parser = CustomOutputParser1()\n",
    "    elif isinstance(llm, ChatOpenAI):\n",
    "        prompt_to_use = BASE_CHAT_TEMPLATE.partial(tools=\"\\n\\n\".join([tk.get_typescript_namespace() for tk in toolkits]))\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        stop=[\"\\nObservation:\"]\n",
    "        output_parser = CustomOutputParser()\n",
    "    else:\n",
    "        raise ValueError\n",
    "    prompt_to_use = anthropic_prompt.partial(tools=\"\\n\\n\".join([tk.get_typescript_namespace() for tk in toolkits]))\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", )\n",
    "    stop=[\"[TOOL_USE_END]\"]\n",
    "    output_parser = CustomOutputParser1()\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_to_use)\n",
    "    agent = LLMSingleActionAgent(llm_chain=llm_chain, output_parser=output_parser, stop=stop)\n",
    "    \n",
    "    tools = []\n",
    "    for tk in toolkits:\n",
    "        tools.extend(tk.get_tools())\n",
    "    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc799d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_TEST_CASES = [\n",
    "    # Should know the answer to \"whats my name\"\n",
    "    [\n",
    "        {\"input\": \"hi im bob\"},\n",
    "        {\"input\": \"whats my name?\"}\n",
    "    ],\n",
    "    # Should not know the answer to \"whats my name\"\n",
    "    [\n",
    "        {\"input\": \"whats my name?\"}\n",
    "    ],\n",
    "]\n",
    "KLARNA_TEST_CASES = [\n",
    "    \n",
    "    [\n",
    "        {\"input\": \"what are some blue shirts you have available?\"},\n",
    "    ],\n",
    "    [\n",
    "        {\"input\": \"what is the most expensive t-shirt you have?\"},\n",
    "        {\"input\": \"whats the price in dollars?\"},\n",
    "    ],\n",
    "]\n",
    "MILO_TEST_CASES = [\n",
    "    [\n",
    "        {\"input\": \"whats magic today?\"},\n",
    "        {\"input\": \"thanks!\"}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0fb1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS = [\n",
    "    {\n",
    "        \"urls\":[\n",
    "            \"https://www.klarna.com/.well-known/ai-plugin.json\"\n",
    "        ],\n",
    "        \"test_cases\": KLARNA_TEST_CASES\n",
    "    }\n",
    "#     {\n",
    "#         \"urls\":[\n",
    "#             \"https://www.joinmilo.com/.well-known/ai-plugin.json\"\n",
    "#         ],\n",
    "#         \"test_cases\": MILO_TEST_CASES\n",
    "#     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01ef6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI, Anthropic\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = OpenAI(temperature=0, verbose=True)\n",
    "#llm = ChatOpenAI(temperature=0)\n",
    "#llm = Anthropic(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "243cd4c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m [TOOL_USE_BEGIN]const langchain = KlarnaProducts.productsUsingGET({q: \"blue shirt\", size: 10, budget: 100})\u001b[0m\n",
      "[TOOL_USE_END]\u001b[36;1m\u001b[1;3m{'products': [{'name': 'Polo Ralph Lauren Polo Shirt - Blue', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3200135914/Clothing/Polo-Ralph-Lauren-Polo-Shirt-Blue/?utm_source=openai', 'price': '$98.00', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Blue']}, {'name': 'Dickies Original Short Sleeve Work Shirt - Royal Blue', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3200090586/Clothing/Dickies-Original-Short-Sleeve-Work-Shirt-Royal-Blue/?utm_source=openai', 'price': '$24.99', 'attributes': ['Material:Polyester,Cotton', 'Target Group:Man', 'Color:Blue']}, {'name': 'Hugo Boss Paddy Polo Shirt - Open Blue', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3200882220/Clothing/Hugo-Boss-Paddy-Polo-Shirt-Open-Blue/?utm_source=openai', 'price': '$64.19', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Blue']}, {'name': 'Lacoste Slim Fit Petit Pique Polo Shirt - Navy Blue', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3201243180/Clothing/Lacoste-Slim-Fit-Petit-Pique-Polo-Shirt-Navy-Blue/?utm_source=openai', 'price': '$88.95', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Blue']}, {'name': 'Carhartt Long Sleeve T-shirt', 'url': 'https://www.klarna.com/us/shopping/pl/cl359/3202981740/Children-s-Clothing/Carhartt-Long-Sleeve-T-shirt/?utm_source=openai', 'price': '$13.13', 'attributes': ['Material:Polyester,Cotton', 'Color:Gray,Blue,Green', 'Model:Boy', 'Size (Small-Large):S,L,M', 'Size (US):4,5,6,7']}, {'name': 'Carhartt Flame-Resistant Force Long Sleeve T-Shirt - Blue', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3201825866/Clothing/Carhartt-Flame-Resistant-Force-Long-Sleeve-T-Shirt-Blue/?utm_source=openai', 'price': '$69.99', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Gray,Blue,Beige']}, {'name': 'Psycho Bunny Mens Copa Gradient Logo Graphic Tee', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3203663222/Clothing/Psycho-Bunny-Mens-Copa-Gradient-Logo-Graphic-Tee/?utm_source=openai', 'price': '$35.00', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:White,Blue,Black,Orange']}, {'name': 'La Martina Blue Shirt', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3205111681/Clothing/La-Martina-Blue-Shirt/?utm_source=openai', 'price': '$85.00', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Blue']}, {'name': 'Old Navy Softest Crew Neck T-shirt for Boys - Ink Blue (898709)', 'url': 'https://www.klarna.com/us/shopping/pl/cl359/3201096539/Children-s-Clothing/Old-Navy-Softest-Crew-Neck-T-shirt-for-Boys-Ink-Blue-%28898709%29/?utm_source=openai', 'price': '$9.99', 'attributes': ['Material:Polyester,Cotton', 'Color:Blue', 'Model:Boy', 'Size (Small-Large):XL,L,XXL']}, {'name': 'La Martina Light Blue Shirt', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3205112484/Clothing/La-Martina-Light-Blue-Shirt/?utm_source=openai', 'price': '$38.00', 'attributes': ['Target Group:Man', 'Color:Blue,Multicolor']}]}\u001b[0m\u001b[32;1m\u001b[1;3mI found 10 blue shirts that are available. Here are some of them: Polo Ralph Lauren Polo Shirt - Blue, Dickies Original Short Sleeve Work Shirt - Royal Blue, Hugo Boss Paddy Polo Shirt - Open Blue, Lacoste Slim Fit Petit Pique Polo Shirt - Navy Blue, Carhartt Long Sleeve T-shirt, Carhartt Flame-Resistant Force Long Sleeve T-Shirt - Blue, Psycho Bunny Mens Copa Gradient Logo Graphic Tee, La Martina Blue Shirt, Old Navy Softest Crew Neck T-shirt for Boys - Ink Blue (898709), La Martina Light Blue Shirt.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m [TOOL_USE_BEGIN]const langchain = KlarnaProducts.productsUsingGET({q: \"t-shirt\", size: 1, budget: 9999})\u001b[0m\n",
      "[TOOL_USE_END]\u001b[36;1m\u001b[1;3m{'products': [{'name': 'T-shirt', 'url': 'https://www.klarna.com/us/shopping/pl/cl10001/3203506327/Clothing/T-shirt/?utm_source=openai', 'price': '$29.99', 'attributes': ['Material:Cotton', 'Target Group:Man', 'Color:Gray,White,Blue,Black,Orange']}]}\u001b[0m\u001b[32;1m\u001b[1;3mThe most expensive t-shirt we have is a cotton t-shirt for men in gray, white, blue, black, or orange for $29.99. You can find it here: https://www.klarna.com/us/shopping/pl/cl10001/3203506327/Clothing/T-shirt/?utm_source=openai.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m The price in dollars is $29.99. You can find it here: https://www.klarna.com/us/shopping/pl/cl10001/3203506327/Clothing/T-shirt/?utm_source=openai.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for test in TESTS:\n",
    "    toolkits = get_toolkits(test[\"urls\"])\n",
    "    for tc in test[\"test_cases\"]:\n",
    "        agent = get_agent(toolkits, llm)\n",
    "        for entry in tc:\n",
    "            foo = agent(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa4ea23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what are some blue shirts you have available?',\n",
       " 'chat_history': '',\n",
       " 'output': 'Here are some blue shirt options from Klarna:\\nPolo Ralph Lauren Polo Shirt - Blue\\nDickies Original Short Sleeve Work Shirt - Royal Blue\\nHugo Boss Paddy Polo Shirt - Open Blue\\nLacoste Slim Fit Petit Pique Polo Shirt - Navy Blue\\nCarhartt Long Sleeve T-shirt (available in gray, blue and green)'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a1ae384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what are some blue shirts you have available?',\n",
       " 'chat_history': '',\n",
       " 'output': 'I found 10 blue shirts that may interest you. Here are some of them: Polo Ralph Lauren Polo Shirt - Blue, Dickies Original Short Sleeve Work Shirt - Royal Blue, Hugo Boss Paddy Polo Shirt - Open Blue, Lacoste Slim Fit Petit Pique Polo Shirt - Navy Blue, Carhartt Long Sleeve T-shirt, Carhartt Flame-Resistant Force Long Sleeve T-Shirt - Blue, Psycho Bunny Mens Copa Gradient Logo Graphic Tee, La Martina Blue Shirt, Old Navy Softest Crew Neck T-shirt for Boys - Ink Blue (898709), La Martina Light Blue Shirt.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc6dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "18784188d7ecd866c0586ac068b02361a6896dc3a29b64f5cc957f09c590acef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
