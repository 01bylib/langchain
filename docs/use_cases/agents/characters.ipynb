{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9732067-71c7-46f7-ad09-381b3bf21a27",
   "metadata": {},
   "source": [
    "# LangChain Implementation of Generative Agents: Interactive Simulacra of Human Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install termcolor > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8851c370-b395-4b80-a79d-486a38ffc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from termcolor import colored\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import BaseLanguageModel, Document\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1649-d88f-4973-b655-7042975cde7e",
   "metadata": {},
   "source": [
    "## Key Components\n",
    "- Observational loop\n",
    "   - Need to connect to some world. Can simulate\n",
    "- Memory - 2 types\n",
    "   1. Observations - list/stack of observations\n",
    "   2. Reflections - Syntheses over recent history\n",
    "- Memory Retrieval\n",
    "   - Weighted sum of recency and saliency\n",
    "- Planning / Plan update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0fe498-da9d-4c17-a815-cd9b49d22a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(max_tokens=1500) # Can be any LLM you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043e5203-6a41-431c-9efa-3e1743d7d25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerativeAgent(BaseModel):\n",
    "    \"\"\"A character with memory and innate characteristics.\"\"\"\n",
    "    \n",
    "    name: str\n",
    "    age: int\n",
    "    traits: str\n",
    "    \"\"\"The traits of the character you wish not to change.\"\"\"\n",
    "    status: str\n",
    "    \"\"\"Current activities of the character.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    memory_retriever: TimeWeightedVectorStoreRetriever\n",
    "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
    "    verbose: bool = False\n",
    "    \n",
    "    reflection_threshold: Optional[float] = None\n",
    "    \"\"\"When the total 'importance' of memories exceeds the above threshold, stop to reflect.\"\"\"\n",
    "    \n",
    "    current_plan: List[str] = []\n",
    "    \"\"\"The current plan of the agent.\"\"\"\n",
    "    \n",
    "    summary: str = \"\"  #: :meta private:\n",
    "    summary_refresh_seconds: int= 3600  #: :meta private:\n",
    "    last_refreshed: datetime =Field(default_factory=datetime.now)  #: :meta private:\n",
    "    daily_summaries: List[str] #: :meta private:\n",
    "    memory_importance: float = 0.0 #: :meta private:\n",
    "    max_tokens_limit: int = 1200 #: :meta private:\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_list(text: str) -> List[str]:\n",
    "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
    "        lines = re.split(r'\\n', text.strip())\n",
    "        return [re.sub(r'^\\s*\\d+\\.\\s*', '', line).strip() for line in lines]\n",
    "\n",
    "\n",
    "    def _compute_agent_summary(self):\n",
    "        \"\"\"\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"How would you summarize {name}'s core characteristics given the\"\n",
    "            +\" following statements:\\n\"\n",
    "            +\"{related_memories}\"\n",
    "            + \"Do not embellish.\"\n",
    "            +\"\\n\\nSummary: \"\n",
    "        )\n",
    "        # The agent seeks to think about their core characteristics.\n",
    "        relevant_memories = self.fetch_memories(f\"{self.name}'s core characteristics\")\n",
    "        relevant_memories_str = \"\\n\".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(name=self.name, related_memories=relevant_memories_str).strip()\n",
    "    \n",
    "    def _get_topics_of_reflection(self, last_k: int = 50) -> Tuple[str, str, str]:\n",
    "        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{observations}\\n\\n\"\n",
    "            + \"Given only the information above, what are the 3 most salient\"\n",
    "            + \" high-level questions we can answer about the subjects in the statements?\"\n",
    "            + \" Provide each question on a new line.\\n\\n\"\n",
    "        )\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
    "        observation_str = \"\\n\".join([o.page_content for o in observations])\n",
    "        result = reflection_chain.run(observations=observation_str)\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def _get_insights_on_topic(self, topic: str) -> List[str]:\n",
    "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Statements about {topic}\\n\"\n",
    "            +\"{related_statements}\\n\\n\"\n",
    "            + \"What 5 high-level insights can you infer from the above statements?\"\n",
    "            + \" (example format: insight (because of 1, 5, 3))\"\n",
    "        )\n",
    "        related_memories = self.fetch_memories(topic)\n",
    "        related_statements = \"\\n\".join([f\"{i+1}. {memory.page_content}\" \n",
    "                                        for i, memory in \n",
    "                                        enumerate(related_memories)])\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        result = reflection_chain.run(topic=topic, related_statements=related_statements)\n",
    "        # TODO: Parse the connections between memories and insights\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def pause_to_reflect(self) -> List[str]:\n",
    "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
    "        print(colored(f\"Character {self.name} is reflecting\", \"blue\"))\n",
    "        new_insights = []\n",
    "        topics = self._get_topics_of_reflection()\n",
    "        for topic in topics:\n",
    "            insights = self._get_insights_on_topic( topic)\n",
    "            for insight in insights:\n",
    "                self.add_memory(insight)\n",
    "            new_insights.extend(insights)\n",
    "        return new_insights\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _score_memory_importance(self, memory_content: str) -> float:\n",
    "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "         \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
    "         +\" (e.g., brushing teeth, making bed) and 10 is\"\n",
    "         + \" extremely poignant (e.g., a break up, college\"\n",
    "         + \" acceptance), rate the likely poignancy of the\"\n",
    "         + \" following piece of memory. Respond with a single integer.\"\n",
    "         + \"\\nMemory: {memory_content}\"\n",
    "         + \"\\nRating: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        score = chain.run(memory_content=memory_content).strip()\n",
    "        return float(score[0]) / 10\n",
    "    \n",
    "    def add_memory(self, memory_content: str) -> List[str]:\n",
    "        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n",
    "        importance_score = self._score_memory_importance(memory_content)\n",
    "        self.memory_importance += importance_score\n",
    "        document = Document(page_content=memory_content, metadata={\"importance\": importance_score})\n",
    "        result = self.memory_retriever.add_documents([document])\n",
    "        if (self.reflection_threshold is not None \n",
    "            and self.memory_importance > self.reflection_threshold\n",
    "            and self.status != \"Reflecting\"):\n",
    "            old_status = self.status\n",
    "            self.status = \"Reflecting\"\n",
    "            self.pause_to_reflect()\n",
    "            # Hack to clear the importance from reflection\n",
    "            self.memory_importance = 0.0\n",
    "            self.status = old_status\n",
    "        return result\n",
    "    \n",
    "    def fetch_memories(self, observation: str) -> List[Document]:\n",
    "        \"\"\"Fetch related memories.\"\"\"\n",
    "        return self.memory_retriever.get_relevant_documents(observation)\n",
    "    \n",
    "        \n",
    "    def get_summary(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        since_refresh = (current_time - self.last_refreshed).seconds\n",
    "        if not self.summary or since_refresh >= self.summary_refresh_seconds or force_refresh:\n",
    "            self.summary = self._compute_agent_summary()\n",
    "            self.last_refreshed = current_time\n",
    "        return (\n",
    "            f\"Name: {self.name} (age: {self.age})\"\n",
    "            +f\"\\nInnate traits: {self.traits}\"\n",
    "            +f\"\\n{self.summary}\"\n",
    "        )\n",
    "    \n",
    "    def get_full_header(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n",
    "        summary = self.get_summary(force_refresh=force_refresh)\n",
    "        current_time_str =  datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        return f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n",
    "\n",
    "    \n",
    "    \n",
    "    def _get_entity_from_observation(self, observation: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the observed entity in the following observation? {observation}\"\n",
    "            +\"\\nEntity=\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(observation=observation).strip()\n",
    "\n",
    "    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the {entity} doing in the following observation? {observation}\"\n",
    "            +\"\\nThe {entity} is\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(entity=entity_name, observation=observation).strip()\n",
    "    \n",
    "    def _format_memories_to_summarize(self, relevant_memories: List[Document]) -> str:\n",
    "        content_strs = set()\n",
    "        content = []\n",
    "        for mem in relevant_memories:\n",
    "            if mem.page_content in content_strs:\n",
    "                continue\n",
    "            content_strs.add(mem.page_content)\n",
    "            created_time = mem.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "            content.append(f\"- {created_time}: {mem.page_content.strip()}\")\n",
    "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
    "    \n",
    "    def summarize_related_memories(self, observation: str) -> str:\n",
    "        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n",
    "        entity_name = self._get_entity_from_observation(observation)\n",
    "        entity_action = self._get_entity_action(observation, entity_name)\n",
    "        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n",
    "        relevant_memories = self.fetch_memories(q1) # Fetch memories related to the agent's relationship with the entity\n",
    "        q2 = f\"{entity_name} is {entity_action}\"\n",
    "        relevant_memories += self.fetch_memories(q2) # Fetch things related to the entity-action pair\n",
    "        context_str = self._format_memories_to_summarize(relevant_memories)\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{q1}?\\nContext from memory:\\n{context_str}\\nRelevant context: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(q1=q1, context_str=context_str.strip()).strip()\n",
    "    \n",
    "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
    "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
    "        result = []\n",
    "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
    "            if consumed_tokens >= self.max_tokens_limit:\n",
    "                break\n",
    "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
    "            if consumed_tokens < self.max_tokens_limit:\n",
    "                result.append(doc.page_content) \n",
    "        return \"; \".join(result[::-1])\n",
    "    \n",
    "    def _generate_reaction(\n",
    "        self,\n",
    "        observation: str,\n",
    "        suffix: str\n",
    "    ) -> str:\n",
    "        \"\"\"React to a given observation.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "                \"{agent_summary_description}\"\n",
    "                +\"\\nIt is {current_time}.\"\n",
    "                +\"\\n{agent_name}'s status: {agent_status}\"\n",
    "                + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n",
    "                +\"\\n{relevant_memories}\"\n",
    "                +\"\\nMost recent observations: {recent_observations}\"\n",
    "                + \"\\nObservation: {observation}\"\n",
    "                + \"\\n\\n\" + suffix\n",
    "        )\n",
    "        agent_summary_description = self.get_summary()\n",
    "        relevant_memories_str = self.summarize_related_memories(observation)\n",
    "        current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        kwargs = dict(agent_summary_description=agent_summary_description,\n",
    "                      current_time=current_time_str,\n",
    "                      relevant_memories=relevant_memories_str,\n",
    "                      agent_name=self.name,\n",
    "                      observation=observation,\n",
    "                     agent_status=self.status)\n",
    "        consumed_tokens = self.llm.get_num_tokens(prompt.format(recent_observations=\"\", **kwargs))\n",
    "        kwargs[\"recent_observations\"] = self._get_memories_until_limit(consumed_tokens)\n",
    "        action_prediction_chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        result = action_prediction_chain.run(**kwargs)\n",
    "        return result.strip()\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    # Below are methods that can be used to generate a daily plan. They are not\n",
    "    # required for simple conversations, but can be useful for inducing context with\n",
    "    # a virtual game. This works by\n",
    "    # 1. Generate a coarse plan of the day based on the agent's \"qualities\",\n",
    "    #     yesterday's activities, and the current day.\n",
    "    # 2. Refine each step to an hour-by-hour plan.\n",
    "    # 3. Refine each hourly step to 5-15 minute intervals.\n",
    "    ###############################################################################\n",
    "    def _create_coarse_plan(self, verbose: bool = False) -> List[str]:\n",
    "        previous_day_summary = self.daily_summaries[-1]\n",
    "        current_date = datetime.now()\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Name: {name} (age: {age})\"\n",
    "            +\"\\nInnate traits: {innate_traits}\"\n",
    "            + '\\nOn {previous_day}, {name}'\n",
    "            + \" {previous_day_summary}\"\n",
    "            + '\\nToday is {current_day}.'\n",
    "            + \" Here is {name}'s plan today\"\n",
    "            + \" in broad strokes:\"\n",
    "            + \"\\n1. \"\n",
    "        )\n",
    "        previous_day = (current_date - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "        current_day = current_date.strftime(\"%A %B %d\")\n",
    "        coarse_planner = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        result = coarse_planner.run(name=self.name,\n",
    "                                    current_day=current_day,\n",
    "                                    age=self.age,\n",
    "                                    innate_traits=self.traits,\n",
    "                                    previous_day=previous_day,\n",
    "                                    previous_day_summary=previous_day_summary\n",
    "                                   )\n",
    "        return self._parse_list(result)\n",
    "\n",
    "    def _decompose_step(self, high_level_plan: List[str], target_granularity: str, verbose: bool = False) -> List[str]:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Today's High Level Plan: {high_level_plan}\"\n",
    "            + '\\nBelow is a detailed plan for the whole day broken into {target_granularity}'\n",
    "            + \"-long chunks:\"\n",
    "            + \"\\n1. \"\n",
    "        )\n",
    "        decomposing_planner = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        high_level_plan_str = \" \".join(high_level_plan)\n",
    "        result = decomposing_planner.run(\n",
    "            high_level_plan=high_level_plan_str,\n",
    "            target_granularity=target_granularity,\n",
    "        )\n",
    "        return self._parse_list(result)\n",
    "\n",
    "    def _decompose_plan(\n",
    "            self,\n",
    "            high_level_plan: List[str],\n",
    "            granularities: List[str], # hour, 5-15 minute\n",
    "            verbose: bool = False\n",
    "        ) -> List[str]:\n",
    "        result = high_level_plan\n",
    "        for granularity in granularities:\n",
    "            # TODO: We could recurse on each step but then there may end up being\n",
    "            # a need to rectify between windows\n",
    "            result = self._decompose_step(result, granularity, verbose=verbose)\n",
    "            result = [task for task in result if task.strip()]\n",
    "        return result\n",
    "\n",
    "    def generate_full_plan(self, verbose: bool = False) -> List[str]:\n",
    "        coarse_plan = self._create_coarse_plan()\n",
    "        today = datetime.now()\n",
    "        # Save to memory stream\n",
    "        self.add_memory(f\"{self.name}'s initial plan for {today.strftime('%A %B %d')}: {' '.join(coarse_plan)}\")\n",
    "        full_plan = self._decompose_plan(\n",
    "            coarse_plan, \n",
    "            [\"hour\", \"5-15 minute\"],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Save to memory stream\n",
    "        # Unsure if this is done\n",
    "        self.add_memory(f\"{self.name}'s full plan for {today.strftime('%A %B %d')}: {' '.join(full_plan)}\")\n",
    "        return full_plan\n",
    "    \n",
    "    def create_daily_plan(self, verbose: bool = False) -> List[str]:\n",
    "        full_plan = self.generate_full_plan(verbose=verbose)\n",
    "        self.current_plan = full_plan\n",
    "        return full_plan\n",
    "    \n",
    "    def update_todays_plan(self, observation: str, reaction: str, verbose: bool = False) -> List[str]:\n",
    "        \"\"\"When the agent makes a reaction to an observation, update their daily plan if needed.\"\"\"\n",
    "        if self.current_plan is None:\n",
    "            return self.create_daily_plan(verbose=verbose)\n",
    "        full_plan = self.current_plan\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{agent_summary_description}\"\n",
    "            +\"\\nIt is {current_time}.\"\n",
    "            +\"\\n{name} observed {observation} and had the following reaction: {reaction}.\"\n",
    "            +\"\\n{name}'s original plan for the rest of the day:\\n\"\n",
    "            +\"{original_plan}\"\n",
    "            +\"\\nIf this reaction influences the plan, respond with the updated plan at a 5-15 minute granularity. If not, return the original plan unchanged.\\n\"\n",
    "            +\"(Possibly) Updated Plan:\\n\\n\"\n",
    "            )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        already_completed = []\n",
    "        original_plan = []\n",
    "        for item in full_plan:\n",
    "            split_item = item.split(' - ')\n",
    "            time_format = '%I:%M%p'\n",
    "            try:\n",
    "                time_obj = datetime.strptime(split_item[0], time_format)\n",
    "            except:\n",
    "                original_plan.append(item) # TODO: better handle errors\n",
    "            if time_obj.time() > datetime.now().time():\n",
    "                original_plan.append(item)\n",
    "            else:\n",
    "                already_completed.append(item)\n",
    "        current_plan_str = \"\\n\".join([f\"{plan}\" for plan in original_plan])\n",
    "        result = chain.run(\n",
    "            agent_summary_description=self.get_summary(), \n",
    "            current_time = current_time_str,\n",
    "            name=self.name,\n",
    "            observation=observation,\n",
    "            reaction=reaction,\n",
    "            original_plan=current_plan_str)\n",
    "        new_plan = self._parse_list(result)\n",
    "        return already_completed + new_plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c5223-889f-4799-a01b-1f4d50593d95",
   "metadata": {},
   "source": [
    "## Functions for interactions\n",
    "\n",
    "Characters are meant for interactions and actions. Let's define a few functions to parse responses to observations that can be connected to dialogue flows or virtual worlds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10834185-76b1-4d1d-a84c-edb07a31cb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_reaction(agent, observation) -> Tuple[bool, str]:\n",
    "    call_to_action_template = (\n",
    "        \"Should {agent_name} react to the observation, and if so,\"\n",
    "        +\" what would be an appropriate reaction? Respond in one line.\"\n",
    "        +' If the action is to engage in dialogue, write:\\nSAY: \"what to say\"'\n",
    "        +\"\\notherwise, write:\\nREACT: {agent_name}'s reaction (if anything).\\nEither do nothing, react, or say something but not both.\\n\\n\"\n",
    "    )\n",
    "    full_result = agent._generate_reaction(observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    agent.add_memory(f\"{agent.name} observed {observation} and reacted by {result}\")\n",
    "    if \"REACT:\" in result:\n",
    "        reaction = result.split(\"REACT:\")[-1].strip()\n",
    "        return False, reaction\n",
    "    if \"SAY:\" in result:\n",
    "        return True, result.split(\"SAY:\")[-1].strip()\n",
    "    else:\n",
    "        return False, result\n",
    "\n",
    "def generate_dialogue_response(agent, observation: str):\n",
    "    call_to_action_template = (\n",
    "        'What would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
    "    )\n",
    "    full_result = agent._generate_reaction(observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    if \"GOODBYE:\" in result:\n",
    "        farewell = result.split(\"GOODBYE:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {farewell}\")\n",
    "        return False, farewell\n",
    "    if \"SAY:\" in result:\n",
    "        response_text = result.split(\"SAY:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {response_text}\")\n",
    "        return True, response_text\n",
    "    else:\n",
    "        return False, result\n",
    "        \n",
    "def interview_agent(agent, message: str):\n",
    "    new_message = f\"Person A says {message}\"\n",
    "    return generate_dialogue_response(agent, new_message)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb84dd8-ea8f-4d9b-864a-4677a0347f49",
   "metadata": {},
   "source": [
    "## Create a Character\n",
    "\n",
    "For this example, we will create two characters named \"Tommie\" and \"Eve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608c0272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tommie = GenerativeAgent(name=\"Tommie\", \n",
    "              age=25,\n",
    "              traits=\"anxious, likes design\", # You can add more persistent traits here \n",
    "              status=\"looking for a job\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                   \"Drove across state to move to a new town but doesn't have a job yet.\"\n",
    "               ],\n",
    "               reflection_threshold = 8, # we will give this a relatively low number to show how reflection works\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c524d529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "No statements were provided to summarize Tommie's core characteristics.\n"
     ]
    }
   ],
   "source": [
    "# We can see a current \"Summary\" of a character based on their own perception of self.\n",
    "# It isn't very complete right now since the character doesn't have any memories.\n",
    "print(tommie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can give the character memories directly\n",
    "tommie_memories = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "for memory in tommie_memories:\n",
    "    tommie.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6992b48b-697f-4973-9560-142ef85357d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is observant, nostalgic, tired, and hungry.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-Interview with Character\n",
    "\n",
    "Before sending our character on their way, let's ask them a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I really enjoy design, it\\'s always fascinated me. I\\'ve been working on some projects on my own lately, trying to build up my portfolio. Do you have any suggestions for places to look for design jobs?\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e2e8cc-921e-4816-82f1-66962b2c1055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m actually looking for a job right now. Do you know of any opportunities in the design field?\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you looking forward to doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2521ffc-7050-4ac3-9a18-4cccfc798c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Honestly, my biggest worry right now is finding a job in the design field. It\\'s been a bit of a struggle, but I\\'m trying to stay positive and keep searching. Do you happen to know of any leads or connections that could help me out?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you most worried about today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c3d46-9324-48df-a5c3-9e37fb02eb6d",
   "metadata": {},
   "source": [
    "## Create a plan for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b48b7eb-ac0e-452a-93f6-9655f8da9729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6:00am - Wake up and spend 5 minutes stretching and doing some light yoga to help wake up your body and mind. Spend the next 10 minutes meditating and visualizing a positive and productive day.',\n",
       " '6:15am - Get dressed and start your morning routine. Spend 5 minutes brushing your teeth, washing your face, and getting ready for the day.',\n",
       " '6:20am - Prepare a healthy breakfast to give your body the fuel it needs for the day ahead. Spend 15 minutes cooking and eating your meal.',\n",
       " '6:35am - Spend 10 minutes reviewing your goals and priorities for the day ahead. Write out a to-do list and prioritize the tasks you need to complete.',\n",
       " '6:45am - Spend 15 minutes researching job opportunities in the new town. Use online job boards, local newspapers, and networking sites to find potential leads.',\n",
       " '7:00am - Spend 15 minutes reviewing your list of job opportunities and prioritizing them based on your personal interests and qualifications.',\n",
       " '7:15am - Spend 15 minutes researching the first job opportunity on your list. Look into the company and the job requirements to get a better understanding of what they are looking for.',\n",
       " '7:30am - Spend 15 minutes tailoring your resume and cover letter to the first job opportunity on your list. Highlight your relevant experience and skills to show why you would be a good fit for the position.',\n",
       " '7:45am - Take a 15-minute break to stretch and move your body. Stand up, walk around, and do some light exercises to help increase your energy and focus.',\n",
       " '8:00am - Spend the next hour applying for the first job opportunity on your list. Submit your tailored resume and cover letter, and follow up with any additional information the employer may need.',\n",
       " '9:00am - Take a 15-minute break to check your emails and respond to any messages or notifications.',\n",
       " '9:15am - Spend 15 minutes researching the second job opportunity on your list. Look into the company and the job requirements to get a better understanding of what they are looking for.',\n",
       " '9:30am - Spend 15 minutes tailoring your resume and cover letter to the second job opportunity on your list. Highlight your relevant experience and skills to show why you would be a good fit for the position.',\n",
       " '9:45am - Take a 15-minute break to stretch and move your body. Stand up, walk around, and do some light exercises to help increase your energy and focus.',\n",
       " '10:00am - Spend the next hour applying for the second job opportunity on your list. Submit your tailored resume and cover letter, and follow up with any additional information the employer may need.',\n",
       " '11:00am - Take a 30-minute break and go for a walk to explore the new town. Take in the sights and sounds of your surroundings, and enjoy some fresh air and exercise.',\n",
       " '11:30am - Spend 30 minutes working on a design project to stay productive and engaged. Use your creativity to come up with new ideas and solutions.',\n",
       " '12:00pm - Take a 30-minute break to recharge your batteries. Listen to some music, read a book, or do something else that relaxes and rejuvenates you.',\n",
       " '12:30pm - Spend 30 minutes reviewing your to-do list and prioritizing the tasks you need to complete for the rest of the day.',\n",
       " '1:00pm - Spend 30 minutes researching the third job opportunity on your list. Look into the company and the job requirements to get a better understanding of what they are looking for.',\n",
       " '1:30pm - Spend 30 minutes tailoring your resume and cover letter to the third job opportunity on your list. Highlight your relevant experience and skills to show why you would be a good fit for the position.',\n",
       " '2:00pm - Take a 30-minute break to stretch and move your body. Stand up, walk around, and do some light exercises to help increase your energy and focus.',\n",
       " '2:30pm - Spend the next hour applying for the third job opportunity on your list. Submit your tailored resume and cover letter, and follow up with any additional information the employer may need.',\n",
       " '3:30pm - Take a 15-minute break to check your emails and respond to any messages or notifications.',\n",
       " '3:45pm - Spend 30 minutes working on a design project to stay productive and engaged. Use your creativity to come up with new ideas and solutions.',\n",
       " '4:15pm - Take a 15-minute break to connect with friends or family for emotional support and to stay connected to your support system.',\n",
       " '4:30pm - Spend 30 minutes reviewing your progress and reflecting on your accomplishments for the day.',\n",
       " '5:00pm - Spend an hour cooking a healthy meal for dinner to nourish your body and practice self-care. Use fresh ingredients and take your time to enjoy the process.',\n",
       " '6:00pm - Take a 30-minute break to relax and unwind before bed. Read a book, listen to some music, or do something else that helps you calm down and destress.',\n",
       " '6:30pm - Spend 30 minutes preparing for bed. Turn off your electronics, dim the lights, and create a calm and soothing environment to help you sleep better.',\n",
       " '7:00pm - Spend 30 minutes meditating or doing some light yoga to help you relax and prepare for sleep.',\n",
       " '7:30pm - Get into bed and spend the next 30 minutes reading a book, listening to some music, or doing something else that helps you wind down and fall asleep easier.',\n",
       " '8:00pm - Turn off the lights and go to sleep, knowing that you have done your best to make the most of your day and set yourself up for success in the future.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tommie.create_daily_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
   "metadata": {},
   "source": [
    "## Step through the day's observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have Tommie start going through a day in the life.\n",
    "observations = [\n",
    "    \"Tommie wakes up to the sound of a noisy construction site outside his window.\",\n",
    "    \"Tommie gets out of bed and heads to the kitchen to make himself some coffee.\",\n",
    "    \"Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\",\n",
    "    \"Tommie finally finds the filters and makes himself a cup of coffee.\",\n",
    "    \"The coffee tastes bitter, and Tommie regrets not buying a better brand.\",\n",
    "    \"Tommie checks his email and sees that he has no job offers yet.\",\n",
    "    \"Tommie spends some time updating his resume and cover letter.\",\n",
    "    \"Tommie heads out to explore the city and look for job openings.\",\n",
    "    \"Tommie sees a sign for a job fair and decides to attend.\",\n",
    "    \"The line to get in is long, and Tommie has to wait for an hour.\",\n",
    "    \"Tommie meets several potential employers at the job fair but doesn't receive any offers.\",\n",
    "    \"Tommie leaves the job fair feeling disappointed.\",\n",
    "    \"Tommie stops by a local diner to grab some lunch.\",\n",
    "    \"The service is slow, and Tommie has to wait for 30 minutes to get his food.\",\n",
    "    \"Tommie overhears a conversation at the next table about a job opening.\",\n",
    "    \"Tommie asks the diners about the job opening and gets some information about the company.\",\n",
    "    \"Tommie decides to apply for the job and sends his resume and cover letter.\",\n",
    "    \"Tommie continues his search for job openings and drops off his resume at several local businesses.\",\n",
    "    \"Tommie takes a break from his job search to go for a walk in a nearby park.\",\n",
    "    \"A dog approaches and licks Tommie's feet, and he pets it for a few minutes.\",\n",
    "    \"Tommie sees a group of people playing frisbee and decides to join in.\",\n",
    "    \"Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\",\n",
    "    \"Tommie goes back to his apartment to rest for a bit.\",\n",
    "    \"A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\",\n",
    "    \"Tommie starts to feel frustrated with his job search.\",\n",
    "    \"Tommie calls his best friend to vent about his struggles.\",\n",
    "    \"Tommie's friend offers some words of encouragement and tells him to keep trying.\",\n",
    "    \"Tommie feels slightly better after talking to his friend.\",\n",
    "    \"Tommie decides to go for a jog to clear his mind.\",\n",
    "    \"Tommie jogs through the city and sees some interesting sights.\",\n",
    "    \"Tommie stops to take a picture of a street mural.\",\n",
    "    \"Tommie runs into an old friend from college who now lives in the city.\",\n",
    "    \"They catch up for a few minutes, but Tommie's friend has to leave to attend a meeting.\",\n",
    "    \"Tommie thanks his friend and feels hopeful again.\",\n",
    "    \"Tommie heads back to his apartment to rest and prepare for his upcoming interviews.\",\n",
    "    \"Tommie spends the evening rehearsing his interview pitch.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTommie wakes up to the sound of a noisy construction site outside his window.\u001b[0m Tommie feels annoyed and tries to block out the noise by putting on headphones or earplugs.\n",
      "\u001b[32mTommie gets out of bed and heads to the kitchen to make himself some coffee.\u001b[0m Tommie feels a bit better after drinking the coffee and continues with his job search.\n",
      "\u001b[32mTommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\u001b[0m Tommie feels frustrated and annoyed with himself for not being more prepared.\n",
      "\u001b[32mTommie finally finds the filters and makes himself a cup of coffee.\u001b[0m Tommie takes a deep breath and savors the aroma of freshly brewed coffee.\n",
      "\u001b[32mThe coffee tastes bitter, and Tommie regrets not buying a better brand.\u001b[0m Tommie feels disappointed with the bitter taste and makes a mental note to buy a better brand next time.\n",
      "\u001b[32mTommie checks his email and sees that he has no job offers yet.\u001b[0m Tommie feels discouraged and takes a deep breath, reminding themselves to stay positive and keep applying for jobs.\n",
      "\u001b[32mTommie spends some time updating his resume and cover letter.\u001b[0m Tommie feels productive and accomplished after updating their resume and cover letter.\n",
      "\u001b[32mTommie heads out to explore the city and look for job openings.\u001b[0m Tommie feels hopeful and excited to explore the city and find job openings.\n",
      "\u001b[32mTommie sees a sign for a job fair and decides to attend.\u001b[0m Tommie feels hopeful and motivated to attend the job fair.\n",
      "\u001b[32mThe line to get in is long, and Tommie has to wait for an hour.\u001b[0m Tommie feels anxious and restless while waiting in line for an hour.\n",
      "\u001b[34mCharacter Tommie is reflecting\u001b[0m\n",
      "\u001b[32mTommie meets several potential employers at the job fair but doesn't receive any offers.\u001b[0m Tommie feels disappointed but tries to stay positive and continues applying for jobs.\n",
      "\u001b[32mTommie leaves the job fair feeling disappointed.\u001b[0m Tommie feels disappointed but tries to stay positive and continues applying for jobs.\n",
      "\u001b[32mTommie stops by a local diner to grab some lunch.\u001b[0m Tommie feels relieved to take a break and enjoy some food.\n",
      "\u001b[32mThe service is slow, and Tommie has to wait for 30 minutes to get his food.\u001b[0m Tommie feels annoyed and frustrated with the slow service but tries to stay patient and understanding.\n",
      "\u001b[32mTommie overhears a conversation at the next table about a job opening.\u001b[0m \"Excuse me, I couldn't help but overhear about the job opening. Do you have any more information about it?\"\n",
      "\u001b[32mTommie asks the diners about the job opening and gets some information about the company.\u001b[0m \"Can you tell me more about the job opening and the company? I'm actively searching for job opportunities in the design field.\"\n",
      "\u001b[32mTommie decides to apply for the job and sends his resume and cover letter.\u001b[0m \"Thank you for the information. I will definitely look into applying for the job.\"\n",
      "\u001b[32mTommie continues his search for job openings and drops off his resume at several local businesses.\u001b[0m Tommie feels hopeful and proactive in his job search.\n",
      "\u001b[32mTommie takes a break from his job search to go for a walk in a nearby park.\u001b[0m Tommie feels refreshed and rejuvenated after taking a break and going for a walk in the park.\n",
      "\u001b[32mA dog approaches and licks Tommie's feet, and he pets it for a few minutes.\u001b[0m Tommie feels momentarily happy and enjoys petting the dog, but then continues with his job search.\n",
      "****************************************\n",
      "\u001b[34mAfter 20 observations, Tommie's summary is:\n",
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is a determined and proactive individual who is actively searching for job opportunities in the design field. Despite facing setbacks and challenges, Tommie remains hopeful and positive, taking proactive steps such as attending job fairs and networking to find leads. Tommie has a structured and productive daily routine, including meditation, exercise, and creative work, and is committed to self-care and relaxation. Additionally, Tommie has a fond memory of his childhood dog, Bruno.\u001b[0m\n",
      "****************************************\n",
      "\u001b[32mTommie sees a group of people playing frisbee and decides to join in.\u001b[0m Do nothing.\n",
      "\u001b[32mTommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\u001b[0m Tommie winces in pain and holds his nose, but then laughs it off and continues playing.\n",
      "\u001b[32mTommie goes back to his apartment to rest for a bit.\u001b[0m Tommie takes a moment to rest and recharge before continuing with his job search.\n",
      "\u001b[32mA raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\u001b[0m Tommie cleans up the garbage and disposes of it properly.\n",
      "\u001b[32mTommie starts to feel frustrated with his job search.\u001b[0m Tommie takes a deep breath and reminds themselves of their determination to find a job in the design field.\n",
      "\u001b[32mTommie calls his best friend to vent about his struggles.\u001b[0m \"Hey, can we talk for a bit? I'm feeling really frustrated with my job search and I could use someone to vent to.\"\n",
      "\u001b[32mTommie's friend offers some words of encouragement and tells him to keep trying.\u001b[0m \"Thank you for your support, it means a lot to me.\"\n",
      "\u001b[32mTommie feels slightly better after talking to his friend.\u001b[0m Tommie feels grateful for his friend's support and takes a moment to reflect on their advice before continuing with his job search.\n",
      "\u001b[32mTommie decides to go for a jog to clear his mind.\u001b[0m Tommie puts on his running shoes and heads out for a jog.\n",
      "\u001b[32mTommie jogs through the city and sees some interesting sights.\u001b[0m Tommie feels energized and inspired by the sights of the city during his jog.\n",
      "\u001b[32mTommie stops to take a picture of a street mural.\u001b[0m Tommie smiles and admires the street mural before continuing on their jog.\n",
      "\u001b[32mTommie runs into an old friend from college who now lives in the city.\u001b[0m \"Hey! It's great to see you, how have you been?\"\n",
      "\u001b[32mThey catch up for a few minutes, but Tommie's friend has to leave to attend a meeting.\u001b[0m \"It was great seeing you, let's catch up soon!\"\n",
      "\u001b[32mTommie thanks his friend and feels hopeful again.\u001b[0m \"Thanks for catching up with me, it was great seeing you again.\"\n",
      "\u001b[34mCharacter Tommie is reflecting\u001b[0m\n",
      "\u001b[32mTommie heads back to his apartment to rest and prepare for his upcoming interviews.\u001b[0m Tommie feels relieved to be able to rest and prepare for his upcoming interviews.\n",
      "\u001b[32mTommie spends the evening rehearsing his interview pitch.\u001b[0m Tommie feels prepared and confident for the upcoming interview.\n"
     ]
    }
   ],
   "source": [
    "# Let's send Tommie on their way. We'll check in on their summary every few observations to watch it evolve\n",
    "for i, observation in enumerate(observations):\n",
    "    _, reaction = generate_reaction(tommie, observation)\n",
    "    print(colored(observation, \"green\"), reaction)\n",
    "    if ((i+1) % 20) == 0:\n",
    "        print('*'*40)\n",
    "        print(colored(f\"After {i+1} observations, Tommie's summary is:\\n{tommie.get_summary(force_refresh=True)}\", \"blue\"))\n",
    "        print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62a275-7290-43ca-aa0f-504f3a706d09",
   "metadata": {},
   "source": [
    "## Interview after the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6336ab5d-3074-4831-951f-c9e2cba5dfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"It\\'s been a bit of a rollercoaster, but I\\'m feeling hopeful now. I went for a jog and saw some really inspiring sights in the city, and I also spent the evening rehearsing my interview pitch. It\\'s been a productive day overall. How about you?\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"Tell me about how your day has been going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809ac906-69b7-4326-99ec-af638d32bb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I actually don\\'t drink coffee, but I love tea. How about you?\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How do you feel about coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f733a431-19ea-421a-9101-ae2593a8c626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I actually don\\'t drink coffee, but I love tea. How about you?\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are your thoughts on coffee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9261428-778a-4c0b-b725-bc9e91b71391",
   "metadata": {},
   "source": [
    "## Adding Multiple Characters\n",
    "\n",
    "Let's add a second character to have a conversation with Tommie. Feel free to configure different traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8bbe18-a021-419c-bf1f-23d34732cd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eve = GenerativeAgent(name=\"Eve\", \n",
    "              age=34, \n",
    "              traits=\"curious, helpful\", # You can add more persistent traits here \n",
    "              status=\"N/A\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                  (\"Eve started her new job as a career counselor last week and received her first assignment, a client named Tommie.\")\n",
    "              ],\n",
    "                reflection_threshold = 5,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2745f5-e0da-4abd-98b4-830802ce6698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "eve_memories = [\n",
    "    \"Eve overhears her colleague say something about a new client being hard to work with\",\n",
    "    \"Eve wakes up and hear's the alarm\",\n",
    "    \"Eve eats a boal of porridge\",\n",
    "    \"Eve helps a coworker on a task\",\n",
    "    \"Eve plays tennis with her friend Xu before going to work\",\n",
    "    \"Eve overhears her colleague say something about Tommie being hard to work with\",\n",
    "    \n",
    "]\n",
    "for memory in eve_memories:\n",
    "    eve.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de4726e3-4bb1-47da-8fd9-f317a036fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is attentive to her coworkers, enjoys physical activity, is helpful and cooperative, and has a routine morning.\n"
     ]
    }
   ],
   "source": [
    "print(eve.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837524e9-7f7e-4e9f-b610-f454062f5915",
   "metadata": {},
   "source": [
    "## Pre-conversation interviews\n",
    "\n",
    "\n",
    "Let's \"Interview\" Eve before she speaks with Tommie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cda916d-800c-47bc-a7f9-6a2f19187472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m feeling pretty good today, thanks for asking! How about you?\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How are you feeling about today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "448ae644-0a66-4eb2-a03a-319f36948b37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I don\\'t know much about Tommie, but I overheard someone saying they were hard to work with. Have you worked with them before?\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you know about Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "493fc5b8-8730-4ef8-9820-0f1769ce1691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Oh, interesting. What kind of job is Tommie looking for?\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"Tommie is looking to find a job. What are are some things you'd like to ask him?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b46452a-6c54-4db2-9d87-18597f70fec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sure, I\\'d be happy to help. What kind of experience does Tommie have in the field he\\'s looking for a job in?\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"You'll have to ask him. He may be a bit shy, so I'd appreciate it if you keep the conversation go and ask as many questions as possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780655-1d73-4fcb-a78d-79fd46a20636",
   "metadata": {},
   "source": [
    "## Dialogue between Generative Agents\n",
    "\n",
    "Generative agents are much more complex when they interact with a virtual environment or with each other. Below, we run a simple conversation between Tommie and Eve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "042ea271-4bf1-4247-9082-239a6fea43b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conversation(agents, initial_observation: str, max_turns:int = 25, reflection_frequency: Optional[int] = 5):\n",
    "    _, observation = generate_reaction(agents[1], initial_observation)\n",
    "    print(f\"{agents[1].name}: {observation}\")\n",
    "    turns = 0\n",
    "    while True:\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, reaction = generate_dialogue_response(agent, observation)\n",
    "            print(f\"{agent.name}: {reaction}\")\n",
    "            observation = f\"{agent.name} said {reaction}\"\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True   \n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5462b14-218e-4d85-b035-df57ea8e0f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eve: \"Sure, I'd be happy to share my story and offer advice. I actually got into the industry through a friend who recommended me for a position. How about you?\"\n",
      "Tommie: \"That's great to hear! I'm actually still searching for job opportunities in the design field. Do you have any advice on how I can network and connect with people in the industry?\"\n",
      "Eve: \"Of course, networking is really important in this industry. Have you tried attending industry events or joining professional associations? It's also helpful to reach out to people on LinkedIn and ask for informational interviews. And don't be afraid to ask your friends and colleagues if they know of any job openings. Good luck with your job search!\"\n",
      "Tommie: \"Thank you so much for the advice, Eve. I really appreciate it. I'll definitely look into attending industry events and reaching out to people on LinkedIn. Goodbye!\"\n",
      "Eve: \"You're welcome, Tommie. I'm glad I could offer some helpful advice. Good luck with your job search!\"\n"
     ]
    }
   ],
   "source": [
    "agents = [tommie, eve]\n",
    "run_conversation(agents, \"Hi, Eve. Thanks for agreeing to share your story with me and give me advice. Maybe we can start with how you got into the industry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28fe80-03dc-4399-961d-6e9ee1980216",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's interview our agents after their conversation\n",
    "\n",
    "Since the generative agents retain their memories from the day, we can ask them about their plans, conversations, and other memoreis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4d252f3-fcc1-474c-846e-a7605a6b4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is determined, proactive, and willing to put in a lot of effort to find a job in the design field. They value social support and seek help and networking to find job opportunities. Despite facing setbacks and challenges, Tommie tries to stay positive and productive while exploring the city for job openings. They also reach out to friends to vent about their struggles and remain hopeful and excited about their job search.\n",
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is a helpful and supportive colleague who is willing to offer advice and assistance to others. She is knowledgeable about networking and professional associations in her industry. She is also observant and willing to ask questions to learn more about people and situations. She is a friendly person who engages in casual conversation with others and is willing to share her own experiences. Additionally, she is responsible and punctual in her daily routine.\n"
     ]
    }
   ],
   "source": [
    "# We can see how the agents have \n",
    "print(tommie.get_summary(force_refresh=True))\n",
    "\n",
    "# We can see a current \"Summary\" of a character based on their own perception of self\n",
    "print(eve.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71762558-8fb6-44d7-8483-f5b47fb2a862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"It was great! Eve gave me some really helpful advice on networking and finding job opportunities in the design field. Have you ever attended any industry events or joined professional associations?\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How was your conversation with Eve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "085af3d8-ac21-41ea-8f8b-055c56976a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"It was a positive conversation. Tommie seemed really eager to learn about networking and job searching in the industry. I was happy to offer some advice and hopefully help him in his search.\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How was your conversation with Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b439f3c-7849-4432-a697-2bcc85b89dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I think I covered most of what I wanted to share with Tommie, but if there\\'s anything else he wants to know or if he has any more questions, he knows where to find me. Thanks for asking, Person A.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you wish you would have said to Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb7532-e38f-4278-8dc4-5b95df6c8a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
