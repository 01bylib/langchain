{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9732067-71c7-46f7-ad09-381b3bf21a27",
   "metadata": {},
   "source": [
    "# LangChain Implementation of Generative Agents: Interactive Simulacra of Human Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install termcolor > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8851c370-b395-4b80-a79d-486a38ffc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from termcolor import colored\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import BaseLanguageModel, Document\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1649-d88f-4973-b655-7042975cde7e",
   "metadata": {},
   "source": [
    "## Key Components\n",
    "- Observational loop\n",
    "   - Need to connect to some world. Can simulate\n",
    "- Memory - 2 types\n",
    "   1. Observations - list/stack of observations\n",
    "   2. Reflections - Syntheses over recent history\n",
    "- Memory Retrieval\n",
    "   - Weighted sum of recency and saliency\n",
    "- Planning / Plan update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0fe498-da9d-4c17-a815-cd9b49d22a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(max_tokens=1500) # Can be any LLM you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043e5203-6a41-431c-9efa-3e1743d7d25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerativeAgent(BaseModel):\n",
    "    \"\"\"A character with memory and innate characteristics.\"\"\"\n",
    "    \n",
    "    name: str\n",
    "    age: int\n",
    "    traits: str\n",
    "    \"\"\"The traits of the character you wish not to change.\"\"\"\n",
    "    status: str\n",
    "    \"\"\"Current activities of the character.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    memory_retriever: TimeWeightedVectorStoreRetriever\n",
    "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
    "    verbose: bool = False\n",
    "    \n",
    "    reflection_threshold: Optional[float] = None\n",
    "    \"\"\"When the total 'importance' of memories exceeds the above threshold, stop to reflect.\"\"\"\n",
    "\n",
    "    summary: str = \"\"  #: :meta private:\n",
    "    summary_refresh_seconds: int= 3600  #: :meta private:\n",
    "    last_refreshed: datetime =Field(default_factory=datetime.now)  #: :meta private:\n",
    "    daily_summaries: List[str] #: :meta private:\n",
    "    memory_importance: float = 0.0 #: :meta private:\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_list(text: str) -> List[str]:\n",
    "        lines = re.split(r'\\n', text.strip())\n",
    "        return [re.sub(r'^\\s*\\d+\\.\\s*', '', line).strip() for line in lines]\n",
    "\n",
    "    def _score_memory_importance(self, memory_content: str) -> float:\n",
    "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "         \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
    "         +\" (e.g., brushing teeth, making bed) and 10 is\"\n",
    "         + \" extremely poignant (e.g., a break up, college\"\n",
    "         + \" acceptance), rate the likely poignancy of the\"\n",
    "         + \" following piece of memory. Respond with a single integer.\"\n",
    "         + \"\\nMemory: {memory_content}\"\n",
    "         + \"\\nRating: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        score = chain.run(memory_content=memory_content).strip()\n",
    "        return float(score[0]) / 10\n",
    "\n",
    "    def _compute_agent_summary(self):\n",
    "        \"\"\"\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"How would you summarize {name}'s core characteristics given the\"\n",
    "            +\" following statements:\\n\"\n",
    "            +\"{related_memories}\"\n",
    "            + \"Do not embellish.\"\n",
    "            +\"\\n\\nSummary: \"\n",
    "        )\n",
    "        # The agent seeks to think about their core characteristics.\n",
    "        relevant_memories = self.fetch_memories(f\"{self.name}'s core characteristics\")\n",
    "        relevant_memories_str = \"\\n\".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(name=self.name, related_memories=relevant_memories_str).strip()\n",
    "    \n",
    "    def _get_topics_of_reflection(self, last_k: int = 100) -> Tuple[str, str, str]:\n",
    "        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{observations}\\n\\n\"\n",
    "            + \"Given only the information above, what are the 3 most salient\"\n",
    "            + \" high-level questions we can answer about the subjects in the statements?\"\n",
    "            + \" Provide each question on a new line.\\n\\n\"\n",
    "        )\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
    "        observation_str = \"\\n\".join([o.page_content for o in observations])\n",
    "        result = reflection_chain.run(observations=observation_str)\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def _get_insights_on_topic(self, topic: str) -> List[str]:\n",
    "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Statements about {topic}\\n\"\n",
    "            +\"{related_statements}\\n\\n\"\n",
    "            + \"What 5 high-level insights can you infer from the above statements?\"\n",
    "            + \" (example format: insight (because of 1, 5, 3))\"\n",
    "        )\n",
    "        related_memories = self.fetch_memories(topic)\n",
    "        related_statements = \"\\n\".join([f\"{i+1}. {memory.page_content}\" \n",
    "                                        for i, memory in \n",
    "                                        enumerate(related_memories)])\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        result = reflection_chain.run(topic=topic, related_statements=related_statements)\n",
    "        # TODO: Parse the connections between memories and insights\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def add_memory(self, memory_content: str) -> List[str]:\n",
    "        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n",
    "        importance_score = self._score_memory_importance(memory_content)\n",
    "        self.memory_importance += importance_score\n",
    "        document = Document(page_content=memory_content, metadata={\"importance\": importance_score})\n",
    "        result = self.memory_retriever.add_documents([document])\n",
    "        if (self.reflection_threshold is not None \n",
    "            and self.memory_importance > self.reflection_threshold\n",
    "            and self.status != \"Reflecting\"):\n",
    "            old_status = self.status\n",
    "            self.status = \"Reflecting\"\n",
    "            self.pause_to_reflect()\n",
    "            # Hack to clear the importance from reflection\n",
    "            self.memory_importance = 0.0\n",
    "            self.status = old_status\n",
    "        return result\n",
    "    \n",
    "    def fetch_memories(self, observation: str) -> List[Document]:\n",
    "        \"\"\"Fetch related memories.\"\"\"\n",
    "        return self.memory_retriever.get_relevant_documents(observation)\n",
    "    \n",
    "        \n",
    "    def get_summary(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        since_refresh = (current_time - self.last_refreshed).seconds\n",
    "        if not self.summary or since_refresh >= self.summary_refresh_seconds or force_refresh:\n",
    "            self.summary = self._compute_agent_summary()\n",
    "            self.last_refreshed = current_time\n",
    "        return (\n",
    "            f\"Name: {self.name} (age: {self.age})\"\n",
    "            +f\"\\nInnate traits: {self.traits}\"\n",
    "            +f\"\\n{self.summary}\"\n",
    "        )\n",
    "    \n",
    "    def get_full_header(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n",
    "        summary = self.get_summary(force_refresh=force_refresh)\n",
    "        current_time_str =  datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        return f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n",
    "\n",
    "    def pause_to_reflect(self) -> List[str]:\n",
    "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
    "        print(colored(f\"Character {self.name} is reflecting\", \"blue\"))\n",
    "        new_insights = []\n",
    "        topics = self._get_topics_of_reflection()\n",
    "        for topic in topics:\n",
    "            insights = self._get_insights_on_topic( topic)\n",
    "            for insight in insights:\n",
    "                self.add_memory(insight)\n",
    "            new_insights.extend(insights)\n",
    "        return new_insights\n",
    "    \n",
    "    def _get_entity_from_observation(self, observation: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the observed entity in the following observation? {observation}\"\n",
    "            +\"\\nEntity=\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(observation=observation).strip()\n",
    "\n",
    "    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the {entity} doing in the following observation? {observation}\"\n",
    "            +\"\\nThe {entity} is\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(entity=entity_name, observation=observation).strip()\n",
    "    \n",
    "    def _format_memories_to_summarize(self, relevant_memories: List[Document]) -> str:\n",
    "        content_strs = set()\n",
    "        content = []\n",
    "        for mem in relevant_memories:\n",
    "            if mem.page_content in content_strs:\n",
    "                continue\n",
    "            content_strs.add(mem.page_content)\n",
    "            created_time = mem.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "            content.append(f\"- {created_time}: {mem.page_content.strip()}\")\n",
    "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
    "    \n",
    "    def summarize_related_memories(self, observation: str) -> str:\n",
    "        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n",
    "        entity_name = self._get_entity_from_observation(observation)\n",
    "        entity_action = self._get_entity_action(observation, entity_name)\n",
    "        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n",
    "        relevant_memories = self.fetch_memories(q1) # Fetch memories related to the agent's relationship with the entity\n",
    "        q2 = f\"{entity_name} is {entity_action}\"\n",
    "        relevant_memories += self.fetch_memories(q2) # Fetch things related to the entity-action pair\n",
    "        context_str = self._format_memories_to_summarize(relevant_memories)\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{q1}?\\nContext from memory:\\n{context_str}\\nRelevant context: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(q1=q1, context_str=context_str.strip()).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c5223-889f-4799-a01b-1f4d50593d95",
   "metadata": {},
   "source": [
    "## Functions for interactions\n",
    "\n",
    "Characters are meant for interactions and actions. Let's define a few functions to facilitate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10834185-76b1-4d1d-a84c-edb07a31cb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _generate_reaction(\n",
    "                  agent: GenerativeAgent,\n",
    "                  observation: str,\n",
    "                  call_to_action_templ: str,\n",
    "                  verbose: bool = False\n",
    "                 ) -> str:\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"{agent_summary_description}\"\n",
    "        +\"\\nIt is {current_time}.\"\n",
    "        +\"\\n{agent_name}'s status: {agent_status}\"\n",
    "        + \"\\nObservation: {observation}\"\n",
    "        + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n",
    "        +\"\\n{relevant_memories}\"\n",
    "        + \"\\n\" + call_to_action_templ\n",
    "    )\n",
    "    agent_summary_description = agent.get_summary()\n",
    "    relevant_memories_str = agent.summarize_related_memories(observation)\n",
    "    current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "    action_prediction_chain = LLMChain(llm=agent.llm, prompt=prompt)\n",
    "    kwargs = dict(agent_summary_description=agent_summary_description,\n",
    "                  current_time=current_time_str,\n",
    "                  relevant_memories=relevant_memories_str,\n",
    "                  agent_name=agent.name,\n",
    "                  observation=observation,\n",
    "                 agent_status=agent.status)\n",
    "    result = action_prediction_chain.run(**kwargs)\n",
    "    return result.strip()\n",
    "\n",
    "def generate_reaction(agent, observation) -> Tuple[bool, str]:\n",
    "    call_to_action_template = (\n",
    "        \"Should {agent_name} react to the observation, and if so,\"\n",
    "        +\" what would be an appropriate reaction? Respond in one line.\"\n",
    "        +' If the action is to engage in dialogue, write:\\nSAY: \"what to say\"'\n",
    "        +\"\\notherwise, write:\\nREACT: {agent_name}'s reaction (if anything).\\nEither do nothing, react, or say something but not both.\\n\\n\"\n",
    "    )\n",
    "    full_result = _generate_reaction(agent, observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    agent.add_memory(f\"{agent.name} observed {observation} and reacted by {result}\")\n",
    "    if \"REACT:\" in result:\n",
    "        reaction = result.split(\"REACT:\")[-1].strip()\n",
    "        return False, reaction\n",
    "    if \"SAY:\" in result:\n",
    "        return True, result.split(\"SAY:\")[-1].strip()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid response: \", result)\n",
    "\n",
    "def generate_dialogue_response(agent, observation: str):\n",
    "    call_to_action_template = (\n",
    "        'What would {agent_name} say? Respond in 1 line. To end the conversation, write:\\nGOODBYE: \"what to say as a farewell\"\\nOtherwise to continue the conversation, write:\\nSAY: \"what to say next\"\\n\\n'\n",
    "    )\n",
    "    full_result = _generate_reaction(agent, observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    if \"GOODBYE:\" in result:\n",
    "        farewell = result.split(\"GOODBYE:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {farewell}\")\n",
    "        return False, farewell\n",
    "    if \"SAY:\" in result:\n",
    "        response_text = result.split(\"SAY:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {response_text}\")\n",
    "        return True, response_text\n",
    "    else:\n",
    "        raise ValueError(\"Invalid response: \", full_result)\n",
    "        \n",
    "def interview_agent(agent, message: str):\n",
    "    new_message = f\"Interviewer says {message}\"\n",
    "    return generate_dialogue_response(agent, new_message)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb84dd8-ea8f-4d9b-864a-4677a0347f49",
   "metadata": {},
   "source": [
    "## Create a Character\n",
    "\n",
    "For this example, we will create two characters named \"Tommie\" and \"Eve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "608c0272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tommie = GenerativeAgent(name=\"Tommie\", \n",
    "              age=25,\n",
    "              traits=\"anxious, likes design\", # You can add more persistent traits here \n",
    "              status=\"looking for a job\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                   \"Drove across state to move to a new town but doesn't have a job yet.\"\n",
    "               ],\n",
    "               reflection_threshold = 10, # we will give this a relatively low number to show how reflection works\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c524d529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "No statements provided.\n"
     ]
    }
   ],
   "source": [
    "# We can see a current \"Summary\" of a character based on their own perception of self.\n",
    "# It isn't very complete right now since the character doesn't have any memories.\n",
    "print(tommie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can give the character memories directly\n",
    "tommie_memories = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "for memory in tommie_memories:\n",
    "    tommie.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6992b48b-697f-4973-9560-142ef85357d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is observant, has memories of his past, is affected by environmental factors such as noise, and has basic physical needs like rest and food.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
   "metadata": {},
   "source": [
    "## Pre-Interview with Character\n",
    "\n",
    "Before sending our character on their way, let's ask them a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I enjoy design and creating visually appealing content.\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71e2e8cc-921e-4816-82f1-66962b2c1055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m looking forward to exploring new design opportunities.\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you looking forward to doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2521ffc-7050-4ac3-9a18-4cccfc798c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCharacter Tommie is reflecting\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"I\\'m most worried about finding a job that allows me to use my design skills to their fullest potential.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you most worried about today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
   "metadata": {},
   "source": [
    "## Step through the day's observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have Tommie start going through a day in the life.\n",
    "observations = [\n",
    "    \"Tommie wakes up to the sound of a noisy construction site outside his window.\",\n",
    "    \"Tommie gets out of bed and heads to the kitchen to make himself some coffee.\",\n",
    "    \"Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\",\n",
    "    \"Tommie finally finds the filters and makes himself a cup of coffee.\",\n",
    "    \"The coffee tastes bitter, and Tommie regrets not buying a better brand.\",\n",
    "    \"Tommie checks his email and sees that he has no job offers yet.\",\n",
    "    \"Tommie spends some time updating his resume and cover letter.\",\n",
    "    \"Tommie heads out to explore the city and look for job openings.\",\n",
    "    \"Tommie sees a sign for a job fair and decides to attend.\",\n",
    "    \"The line to get in is long, and Tommie has to wait for an hour.\",\n",
    "    \"Tommie meets several potential employers at the job fair but doesn't receive any offers.\",\n",
    "    \"Tommie leaves the job fair feeling disappointed.\",\n",
    "    \"Tommie stops by a local diner to grab some lunch.\",\n",
    "    \"The service is slow, and Tommie has to wait for 30 minutes to get his food.\",\n",
    "    \"Tommie overhears a conversation at the next table about a job opening.\",\n",
    "    \"Tommie asks the diners about the job opening and gets some information about the company.\",\n",
    "    \"Tommie decides to apply for the job and sends his resume and cover letter.\",\n",
    "    \"Tommie continues his search for job openings and drops off his resume at several local businesses.\",\n",
    "    \"Tommie takes a break from his job search to go for a walk in a nearby park.\",\n",
    "    \"A dog approaches and licks Tommie's feet, and he pets it for a few minutes.\",\n",
    "    \"Tommie sees a group of people playing frisbee and decides to join in.\",\n",
    "    \"Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\",\n",
    "    \"Tommie goes back to his apartment to rest for a bit.\",\n",
    "    \"A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\",\n",
    "    \"Tommie takes a nap but has trouble sleeping because of the noisy construction site outside his window.\",\n",
    "    \"Tommie wakes up feeling even more tired than before.\",\n",
    "    \"Tommie decides to watch some TV to relax.\",\n",
    "    \"The show he's watching is a repeat, and he gets bored after a few minutes.\",\n",
    "    \"Tommie sees a commercial for a new energy drink and decides to try it.\",\n",
    "    \"The energy drink tastes terrible, and Tommie regrets buying it.\",\n",
    "    \"Tommie starts to feel frustrated with his job search.\",\n",
    "    \"Tommie calls his best friend to vent about his struggles.\",\n",
    "    \"Tommie's friend offers some words of encouragement and tells him to keep trying.\",\n",
    "    \"Tommie feels slightly better after talking to his friend.\",\n",
    "    \"Tommie decides to go for a jog to clear his mind.\",\n",
    "    \"Tommie jogs through the city and sees some interesting sights.\",\n",
    "    \"Tommie stops to take a picture of a street mural.\",\n",
    "    \"Tommie runs into an old friend from college who now lives in the city.\",\n",
    "    \"They catch up for a few minutes, but Tommie's friend has to leave to attend a meeting.\",\n",
    "    \"Tommie thanks his friend and feels hopeful again.\",\n",
    "    \"Tommie heads back to his apartment to rest and prepare for his upcoming interviews.\",\n",
    "    \"Tommie spends the evening rehearsing his interview pitch.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reaction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, observation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(observations):\n\u001b[1;32m      3\u001b[0m     _, recation \u001b[38;5;241m=\u001b[39m generate_reaction(tommie, observation)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTommie observed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and reacted with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mreaction\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m observations, Tommie\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms summary is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtommie\u001b[38;5;241m.\u001b[39mget_summary()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reaction' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's send Tommie on their way. We'll check in on their summary every few observations to watch it evolve\n",
    "for i, observation in enumerate(observations):\n",
    "    _, reaction = generate_reaction(tommie, observation)\n",
    "    print(f\"Tommie observed {observation} and reacted with: {reaction}\")\n",
    "    if ((i+1) % 10) == 0:\n",
    "        print(f\"After {i+1} observations, Tommie's summary is:\\n{tommie.get_summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bbe18-a021-419c-bf1f-23d34732cd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eve = GenerativeAgent(name=\"Eve\", \n",
    "              age=34, \n",
    "              traits=\"N/A\", # You can add more persistent traits here \n",
    "              status=\"N/A\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                  (\"Eve started her new job as a career counselor last week and received her first assignment, a client named Tommie.\")\n",
    "              ],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2745f5-e0da-4abd-98b4-830802ce6698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "eve_memories = [\n",
    "    \"Eve overhears her colleague say something about a new client being hard to work with\",\n",
    "    \"Eve wakes up and hear's the alarm\",\n",
    "    \"Eve eats a boal of porridge\",\n",
    "    \"Eve helps a coworker on a task\",\n",
    "    \"Eve plays tennis with her friend Xu before going to work\",\n",
    "    \"Eve overhears her colleague say something about Tommie being hard to work with\",\n",
    "    \n",
    "]\n",
    "for memory in eve_memories:\n",
    "    eve.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4726e3-4bb1-47da-8fd9-f317a036fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eve.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5410952-88ac-4d51-a0b1-5568555e6030",
   "metadata": {},
   "source": [
    "## Planning\n",
    "\n",
    "The authors of ...LINK HERE... recognize that simply prompting with current time,\n",
    "agent name/traits, and \"what would you do now\" would result in temporal\n",
    "redundancies/inconsistencies. Much better to develop a full plan of the day. \n",
    "\n",
    "We haven't run ablations on how helpful the recursive plan refinement is, but this is meant to be similar to the process described in the paper:\n",
    "1. Generate a coarse plan of the day based on the agent's \"qualities\", yesterday's activities, and the current day.\n",
    "2. Refine each step to an hour-by-hour plan.\n",
    "3. Refine each hourly step to 5-15 minute intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c198f1-cf6a-41a0-a330-31774fc3925c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _create_coarse_plan(agent: GenerativeAgent, verbose: bool = False) -> List[str]:\n",
    "    previous_day_summary = agent.daily_summaries[-1]\n",
    "    current_date = datetime.now()\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"Name: {name} (age: {age})\"\n",
    "        +\"\\nInnate traits: {innate_traits}\"\n",
    "        + '\\nOn {previous_day}, {name}'\n",
    "        + \" {previous_day_summary}\"\n",
    "        + '\\nToday is {current_day}.'\n",
    "        + \" Here is {name}'s plan today\"\n",
    "        + \" in broad strokes:\"\n",
    "        + \"\\n1. \"\n",
    "    )\n",
    "    previous_day = (current_date - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "    current_day = current_date.strftime(\"%A %B %d\")\n",
    "    coarse_planner = LLMChain(llm=agent.llm, prompt=prompt, verbose=verbose)\n",
    "    result = coarse_planner.run(name=agent.name,\n",
    "                                current_day=current_day,\n",
    "                                age=agent.age,\n",
    "                                innate_traits=agent.traits,\n",
    "                                previous_day=previous_day,\n",
    "                                previous_day_summary=previous_day_summary\n",
    "                               )\n",
    "    return self._parse_list(result)\n",
    "\n",
    "def _decompose_step(agent: GenerativeAgent, high_level_plan: List[str], target_granularity: str, verbose: bool = False) -> List[str]:\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"Today's High Level Plan: {high_level_plan}\"\n",
    "        + '\\nBelow is a detailed plan for the whole day broken into {target_granularity}'\n",
    "        + \"-long chunks:\"\n",
    "        + \"\\n1. \"\n",
    "    )\n",
    "    decomposing_planner = LLMChain(llm=agent.llm, prompt=prompt, verbose=verbose)\n",
    "    high_level_plan_str = \" \".join(high_level_plan)\n",
    "    result = decomposing_planner.run(\n",
    "        high_level_plan=high_level_plan_str,\n",
    "        target_granularity=target_granularity,\n",
    "    )\n",
    "    return self._parse_list(result)\n",
    "\n",
    "def _decompose_plan(\n",
    "        agent: GenerativeAgent,\n",
    "        high_level_plan: List[str],\n",
    "        granularities: List[str], # hour, 5-15 minute\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "    result = high_level_plan\n",
    "    for granularity in granularities:\n",
    "        # TODO: We could recurse on each step but then there may end up being\n",
    "        # a need to rectify between windows\n",
    "        result = _decompose_step(agent, result, granularity, verbose=verbose)\n",
    "    return result\n",
    "\n",
    "def generate_full_plan(agent: GenerativeAgent, verbose: bool = False) -> List[str]:\n",
    "    coarse_plan = _create_coarse_plan(agent)\n",
    "    today = datetime.now()\n",
    "    # Save to memory stream\n",
    "    agent.add_memory(f\"{agent.name}'s initial plan for {today.strftime('%A %B %d')}: {' '.join(coarse_plan)}\")\n",
    "    full_plan = _decompose_plan(\n",
    "        agent,\n",
    "        coarse_plan, \n",
    "        [\"hour\", \"5-15 minute\"],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    # Save to memory stream\n",
    "    # Unsure if this is done\n",
    "    agent.add_memory(f\"{agent.name}'s full plan for {today.strftime('%A %B %d')}: {' '.join(full_plan)}\")\n",
    "    return full_plan\n",
    "\n",
    "def update_todays_plan(agent: GenerativeAgent, full_plan: List[str], observation: str, reaction: str, verbose: bool = False) -> List[str]:\n",
    "    \"\"\"When the agent makes a reaction to an observation, update their daily plan if needed.\"\"\"\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"{agent_summary_description}\"\n",
    "        +\"\\nIt is {current_time}.\"\n",
    "        +\"\\n{name} observed {observation} and had the following reaction: {reaction}.\"\n",
    "        +\"\\n{name}'s original plan for the rest of the day:\\n\"\n",
    "        +\"{original_plan}\"\n",
    "        +\"\\nIf this reaction influences the plan, respond with the updated plan at a 5-15 minute granularity. If not, return the original plan unchanged.\\n\"\n",
    "        +\"(Possibly) Updated Plan:\\n\\n\"\n",
    "        )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "    current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "    already_completed = []\n",
    "    original_plan = []\n",
    "    for item in full_plan:\n",
    "        split_item = item.split(' - ')\n",
    "        time_format = '%I:%M%p'\n",
    "        time_obj = datetime.strptime(split_item[0], time_format)\n",
    "        if time_obj.time() > datetime.now().time():\n",
    "            original_plan.append(item)\n",
    "        else:\n",
    "            already_completed.append(item)\n",
    "    current_plan_str = \"\\n\".join([f\"{plan}\" for plan in original_plan])\n",
    "    result = chain.run(\n",
    "        agent_summary_description=agent.get_summary(), \n",
    "        current_time = current_time_str,\n",
    "        name=agent.name,\n",
    "        observation=observation,\n",
    "        reaction=reaction,\n",
    "        original_plan=current_plan_str)\n",
    "    new_plan = self._parse_list(result)\n",
    "    return already_completed + new_plan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da3fde-bfe5-48f4-a113-07f508041faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tommie_full_plan = generate_full_plan(tommie)\n",
    "tommie_full_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97d07-c580-4446-940e-55e90fd65668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eve_full_plan = generate_full_plan(eve)\n",
    "eve_full_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4c15d-c54b-4bcb-935c-a6b66f194baf",
   "metadata": {},
   "source": [
    "## Acting in the environment\n",
    "\n",
    "\n",
    "Agents can plan and act based on obserations, plans, and personalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10404699-101c-4fda-b16e-0b7ee35f5c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd37bf82-bb0a-4a27-b56f-7538ae2050a3",
   "metadata": {},
   "source": [
    "## Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1795beb-2c61-40e7-8ae8-e1c913f427a1",
   "metadata": {},
   "source": [
    "## GenerativeAgent Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837524e9-7f7e-4e9f-b610-f454062f5915",
   "metadata": {},
   "source": [
    "## Pre-conversation interviews\n",
    "\n",
    "\n",
    "Let's \"Interview\" our characters before their conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13faba2-398d-4f38-ac9d-0a5b05a08150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(tommie, \"How are you feeling about today's plan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459e29c-c1b2-4f16-9719-a258522449a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(tommie, \"How do you feel about Eve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909133c-8aed-40f2-b537-50fc0082405f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(tommie, \"What are looking forward to today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7a587-efdb-465f-8320-c315b216f768",
   "metadata": {},
   "source": [
    "**Now let's \"interview\" Eve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda916d-800c-47bc-a7f9-6a2f19187472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(eve, \"How are you feeling about today's plan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ae644-0a66-4eb2-a03a-319f36948b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(eve, \"How do you feel about Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fc5b8-8730-4ef8-9820-0f1769ce1691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interview_agent(eve, \"What are looking forward to today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780655-1d73-4fcb-a78d-79fd46a20636",
   "metadata": {},
   "source": [
    "### First dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ea271-4bf1-4247-9082-239a6fea43b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conversation(agents, initial_observation: str, max_turns:int = 25, reflection_frequency: Optional[int] = 5):\n",
    "    _, observation = generate_reaction(agents[1], initial_observation)\n",
    "    turns = 0\n",
    "    while True:\n",
    "        if reflection_frequency is not None:\n",
    "            if (turns + 1) % reflection_frequency == 0:\n",
    "                print(\"*\" * 80)\n",
    "                print(colored(\"Reflecting\", \"blue\"))\n",
    "                for agent in agents:\n",
    "                    reflections = \"\\n\".join([f\" - {reflection}\" for reflection in agent.pause_to_reflect()])\n",
    "                    print(colored(f\"{agent.name}'s reflections:\", \"green\"))\n",
    "                    print(colored(f\"{reflections}\", \"blue\"))\n",
    "                print(\"*\" * 80)\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, reaction = generate_dialogue_response(agent, observation)\n",
    "            print(agent.name, reaction)\n",
    "            observation = f\"{agent.name} said {reaction}\"\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True   \n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5462b14-218e-4d85-b035-df57ea8e0f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agents = [tommie, eve]\n",
    "run_conversation(agents, \"Tommie sits down in front of Eve's desk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28fe80-03dc-4399-961d-6e9ee1980216",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's interview our agents after their conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d252f3-fcc1-474c-846e-a7605a6b4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can see how the agents have \n",
    "print(tommie.get_summary(force_refresh=True))\n",
    "\n",
    "# We can see a current \"Summary\" of a character based on their own perception of self\n",
    "print(eve.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71762558-8fb6-44d7-8483-f5b47fb2a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dialogue_response(tommie, \"How do you feel about Eve?\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32ecba-610e-47cf-bfe3-4af7e75479c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_dialogue_response(tommie, \"What are looking forward to today?\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085af3d8-ac21-41ea-8f8b-055c56976a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_dialogue_response(eve, \"How do you feel about Tommie?\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439f3c-7849-4432-a697-2bcc85b89dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_dialogue_response(eve, \"What are looking forward to today?\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298850a-4f81-4afb-a26f-a6ac23ebda21",
   "metadata": {},
   "source": [
    "### Characters can respond to input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160816f6-755d-49b3-ae1f-36b86698ad27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
