{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9732067-71c7-46f7-ad09-381b3bf21a27",
   "metadata": {},
   "source": [
    "# LangChain Implementation of Generative Agents: Interactive Simulacra of Human Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install termcolor > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8851c370-b395-4b80-a79d-486a38ffc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from termcolor import colored\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import BaseLanguageModel, Document\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1649-d88f-4973-b655-7042975cde7e",
   "metadata": {},
   "source": [
    "## Key Components\n",
    "- Observational loop\n",
    "   - Need to connect to some world. Can simulate\n",
    "- Memory - 2 types\n",
    "   1. Observations - list/stack of observations\n",
    "   2. Reflections - Syntheses over recent history\n",
    "- Memory Retrieval\n",
    "   - Weighted sum of recency and saliency\n",
    "- Planning / Plan update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0fe498-da9d-4c17-a815-cd9b49d22a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(max_tokens=1500) # Can be any LLM you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043e5203-6a41-431c-9efa-3e1743d7d25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerativeAgent(BaseModel):\n",
    "    \"\"\"A character with memory and innate characteristics.\"\"\"\n",
    "    \n",
    "    name: str\n",
    "    age: int\n",
    "    traits: str\n",
    "    \"\"\"The traits of the character you wish not to change.\"\"\"\n",
    "    status: str\n",
    "    \"\"\"Current activities of the character.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    memory_retriever: TimeWeightedVectorStoreRetriever\n",
    "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
    "    verbose: bool = False\n",
    "    \n",
    "    reflection_threshold: Optional[float] = None\n",
    "    \"\"\"When the total 'importance' of memories exceeds the above threshold, stop to reflect.\"\"\"\n",
    "    \n",
    "    current_plan: List[str] = []\n",
    "    \"\"\"The current plan of the agent.\"\"\"\n",
    "    \n",
    "    summary: str = \"\"  #: :meta private:\n",
    "    summary_refresh_seconds: int= 3600  #: :meta private:\n",
    "    last_refreshed: datetime =Field(default_factory=datetime.now)  #: :meta private:\n",
    "    daily_summaries: List[str] #: :meta private:\n",
    "    memory_importance: float = 0.0 #: :meta private:\n",
    "    max_tokens_limit: int = 1200 #: :meta private:\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_list(text: str) -> List[str]:\n",
    "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
    "        lines = re.split(r'\\n', text.strip())\n",
    "        return [re.sub(r'^\\s*\\d+\\.\\s*', '', line).strip() for line in lines]\n",
    "\n",
    "\n",
    "    def _compute_agent_summary(self):\n",
    "        \"\"\"\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"How would you summarize {name}'s core characteristics given the\"\n",
    "            +\" following statements:\\n\"\n",
    "            +\"{related_memories}\"\n",
    "            + \"Do not embellish.\"\n",
    "            +\"\\n\\nSummary: \"\n",
    "        )\n",
    "        # The agent seeks to think about their core characteristics.\n",
    "        relevant_memories = self.fetch_memories(f\"{self.name}'s core characteristics\")\n",
    "        relevant_memories_str = \"\\n\".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(name=self.name, related_memories=relevant_memories_str).strip()\n",
    "    \n",
    "    def _get_topics_of_reflection(self, last_k: int = 50) -> Tuple[str, str, str]:\n",
    "        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{observations}\\n\\n\"\n",
    "            + \"Given only the information above, what are the 3 most salient\"\n",
    "            + \" high-level questions we can answer about the subjects in the statements?\"\n",
    "            + \" Provide each question on a new line.\\n\\n\"\n",
    "        )\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
    "        observation_str = \"\\n\".join([o.page_content for o in observations])\n",
    "        result = reflection_chain.run(observations=observation_str)\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def _get_insights_on_topic(self, topic: str) -> List[str]:\n",
    "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Statements about {topic}\\n\"\n",
    "            +\"{related_statements}\\n\\n\"\n",
    "            + \"What 5 high-level insights can you infer from the above statements?\"\n",
    "            + \" (example format: insight (because of 1, 5, 3))\"\n",
    "        )\n",
    "        related_memories = self.fetch_memories(topic)\n",
    "        related_statements = \"\\n\".join([f\"{i+1}. {memory.page_content}\" \n",
    "                                        for i, memory in \n",
    "                                        enumerate(related_memories)])\n",
    "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        result = reflection_chain.run(topic=topic, related_statements=related_statements)\n",
    "        # TODO: Parse the connections between memories and insights\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def pause_to_reflect(self) -> List[str]:\n",
    "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
    "        print(colored(f\"Character {self.name} is reflecting\", \"blue\"))\n",
    "        new_insights = []\n",
    "        topics = self._get_topics_of_reflection()\n",
    "        for topic in topics:\n",
    "            insights = self._get_insights_on_topic( topic)\n",
    "            for insight in insights:\n",
    "                self.add_memory(insight)\n",
    "            new_insights.extend(insights)\n",
    "        return new_insights\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _score_memory_importance(self, memory_content: str) -> float:\n",
    "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "         \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
    "         +\" (e.g., brushing teeth, making bed) and 10 is\"\n",
    "         + \" extremely poignant (e.g., a break up, college\"\n",
    "         + \" acceptance), rate the likely poignancy of the\"\n",
    "         + \" following piece of memory. Respond with a single integer.\"\n",
    "         + \"\\nMemory: {memory_content}\"\n",
    "         + \"\\nRating: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        score = chain.run(memory_content=memory_content).strip()\n",
    "        return float(score[0]) / 10\n",
    "    \n",
    "    def add_memory(self, memory_content: str) -> List[str]:\n",
    "        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n",
    "        importance_score = self._score_memory_importance(memory_content)\n",
    "        self.memory_importance += importance_score\n",
    "        document = Document(page_content=memory_content, metadata={\"importance\": importance_score})\n",
    "        result = self.memory_retriever.add_documents([document])\n",
    "        if (self.reflection_threshold is not None \n",
    "            and self.memory_importance > self.reflection_threshold\n",
    "            and self.status != \"Reflecting\"):\n",
    "            old_status = self.status\n",
    "            self.status = \"Reflecting\"\n",
    "            self.pause_to_reflect()\n",
    "            # Hack to clear the importance from reflection\n",
    "            self.memory_importance = 0.0\n",
    "            self.status = old_status\n",
    "        return result\n",
    "    \n",
    "    def fetch_memories(self, observation: str) -> List[Document]:\n",
    "        \"\"\"Fetch related memories.\"\"\"\n",
    "        return self.memory_retriever.get_relevant_documents(observation)\n",
    "    \n",
    "        \n",
    "    def get_summary(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        since_refresh = (current_time - self.last_refreshed).seconds\n",
    "        if not self.summary or since_refresh >= self.summary_refresh_seconds or force_refresh:\n",
    "            self.summary = self._compute_agent_summary()\n",
    "            self.last_refreshed = current_time\n",
    "        return (\n",
    "            f\"Name: {self.name} (age: {self.age})\"\n",
    "            +f\"\\nInnate traits: {self.traits}\"\n",
    "            +f\"\\n{self.summary}\"\n",
    "        )\n",
    "    \n",
    "    def get_full_header(self, force_refresh: bool = False) -> str:\n",
    "        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n",
    "        summary = self.get_summary(force_refresh=force_refresh)\n",
    "        current_time_str =  datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        return f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n",
    "\n",
    "    \n",
    "    \n",
    "    def _get_entity_from_observation(self, observation: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the observed entity in the following observation? {observation}\"\n",
    "            +\"\\nEntity=\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(observation=observation).strip()\n",
    "\n",
    "    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the {entity} doing in the following observation? {observation}\"\n",
    "            +\"\\nThe {entity} is\"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(entity=entity_name, observation=observation).strip()\n",
    "    \n",
    "    def _format_memories_to_summarize(self, relevant_memories: List[Document]) -> str:\n",
    "        content_strs = set()\n",
    "        content = []\n",
    "        for mem in relevant_memories:\n",
    "            if mem.page_content in content_strs:\n",
    "                continue\n",
    "            content_strs.add(mem.page_content)\n",
    "            created_time = mem.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "            content.append(f\"- {created_time}: {mem.page_content.strip()}\")\n",
    "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
    "    \n",
    "    def summarize_related_memories(self, observation: str) -> str:\n",
    "        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n",
    "        entity_name = self._get_entity_from_observation(observation)\n",
    "        entity_action = self._get_entity_action(observation, entity_name)\n",
    "        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n",
    "        relevant_memories = self.fetch_memories(q1) # Fetch memories related to the agent's relationship with the entity\n",
    "        q2 = f\"{entity_name} is {entity_action}\"\n",
    "        relevant_memories += self.fetch_memories(q2) # Fetch things related to the entity-action pair\n",
    "        context_str = self._format_memories_to_summarize(relevant_memories)\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{q1}?\\nContext from memory:\\n{context_str}\\nRelevant context: \"\n",
    "        )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "        return chain.run(q1=q1, context_str=context_str.strip()).strip()\n",
    "    \n",
    "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
    "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
    "        result = []\n",
    "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
    "            if consumed_tokens >= self.max_tokens_limit:\n",
    "                break\n",
    "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
    "            if consumed_tokens < self.max_tokens_limit:\n",
    "                result.append(doc.page_content) \n",
    "        return \"; \".join(result[::-1])\n",
    "    \n",
    "    def _generate_reaction(\n",
    "        self,\n",
    "        observation: str,\n",
    "        suffix: str\n",
    "    ) -> str:\n",
    "        \"\"\"React to a given observation.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "                \"{agent_summary_description}\"\n",
    "                +\"\\nIt is {current_time}.\"\n",
    "                +\"\\n{agent_name}'s status: {agent_status}\"\n",
    "                + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n",
    "                +\"\\n{relevant_memories}\"\n",
    "                +\"\\nMost recent observations: {recent_observations}\"\n",
    "                + \"\\nObservation: {observation}\"\n",
    "                + \"\\n\\n\" + suffix\n",
    "        )\n",
    "        agent_summary_description = self.get_summary()\n",
    "        relevant_memories_str = self.summarize_related_memories(observation)\n",
    "        current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        kwargs = dict(agent_summary_description=agent_summary_description,\n",
    "                      current_time=current_time_str,\n",
    "                      relevant_memories=relevant_memories_str,\n",
    "                      agent_name=self.name,\n",
    "                      observation=observation,\n",
    "                     agent_status=self.status)\n",
    "        consumed_tokens = self.llm.get_num_tokens(prompt.format(recent_observations=\"\", **kwargs))\n",
    "        kwargs[\"recent_observations\"] = self._get_memories_until_limit(consumed_tokens)\n",
    "        action_prediction_chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        result = action_prediction_chain.run(**kwargs)\n",
    "        return result.strip()\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    # Below are methods that can be used to generate a daily plan. They are not\n",
    "    # required for simple conversations, but can be useful for inducing context with\n",
    "    # a virtual game. This works by\n",
    "    # 1. Generate a coarse plan of the day based on the agent's \"qualities\",\n",
    "    #     yesterday's activities, and the current day.\n",
    "    # 2. Refine each step to an hour-by-hour plan.\n",
    "    # 3. Refine each hourly step to 5-15 minute intervals.\n",
    "    ###############################################################################\n",
    "    def _create_coarse_plan(self, verbose: bool = False) -> List[str]:\n",
    "        previous_day_summary = self.daily_summaries[-1]\n",
    "        current_date = datetime.now()\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Name: {name} (age: {age})\"\n",
    "            +\"\\nInnate traits: {innate_traits}\"\n",
    "            + '\\nOn {previous_day}, {name}'\n",
    "            + \" {previous_day_summary}\"\n",
    "            + '\\nToday is {current_day}.'\n",
    "            + \" Here is {name}'s plan today\"\n",
    "            + \" in broad strokes:\"\n",
    "            + \"\\n1. \"\n",
    "        )\n",
    "        previous_day = (current_date - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "        current_day = current_date.strftime(\"%A %B %d\")\n",
    "        coarse_planner = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        result = coarse_planner.run(name=self.name,\n",
    "                                    current_day=current_day,\n",
    "                                    age=self.age,\n",
    "                                    innate_traits=self.traits,\n",
    "                                    previous_day=previous_day,\n",
    "                                    previous_day_summary=previous_day_summary\n",
    "                                   )\n",
    "        return self._parse_list(result)\n",
    "\n",
    "    def _decompose_step(self, high_level_plan: List[str], target_granularity: str, verbose: bool = False) -> List[str]:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Today's High Level Plan: {high_level_plan}\"\n",
    "            + '\\nBelow is a detailed plan for the whole day broken into {target_granularity}'\n",
    "            + \"-long chunks:\"\n",
    "            + \"\\n1. \"\n",
    "        )\n",
    "        decomposing_planner = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        high_level_plan_str = \" \".join(high_level_plan)\n",
    "        result = decomposing_planner.run(\n",
    "            high_level_plan=high_level_plan_str,\n",
    "            target_granularity=target_granularity,\n",
    "        )\n",
    "        return self._parse_list(result)\n",
    "\n",
    "    def _decompose_plan(\n",
    "            self,\n",
    "            high_level_plan: List[str],\n",
    "            granularities: List[str], # hour, 5-15 minute\n",
    "            verbose: bool = False\n",
    "        ) -> List[str]:\n",
    "        result = high_level_plan\n",
    "        for granularity in granularities:\n",
    "            # TODO: We could recurse on each step but then there may end up being\n",
    "            # a need to rectify between windows\n",
    "            result = self._decompose_step(result, granularity, verbose=verbose)\n",
    "            result = [task for task in result if task.strip()]\n",
    "        return result\n",
    "\n",
    "    def generate_full_plan(self, verbose: bool = False) -> List[str]:\n",
    "        coarse_plan = self._create_coarse_plan()\n",
    "        today = datetime.now()\n",
    "        # Save to memory stream\n",
    "        self.add_memory(f\"{self.name}'s initial plan for {today.strftime('%A %B %d')}: {' '.join(coarse_plan)}\")\n",
    "        full_plan = self._decompose_plan(\n",
    "            coarse_plan, \n",
    "            [\"hour\", \"5-15 minute\"],\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Save to memory stream\n",
    "        # Unsure if this is done\n",
    "        self.add_memory(f\"{self.name}'s full plan for {today.strftime('%A %B %d')}: {' '.join(full_plan)}\")\n",
    "        return full_plan\n",
    "    \n",
    "    def create_daily_plan(self, verbose: bool = False) -> List[str]:\n",
    "        full_plan = self.generate_full_plan(verbose=verbose)\n",
    "        self.current_plan = full_plan\n",
    "        return full_plan\n",
    "    \n",
    "    def update_todays_plan(self, observation: str, reaction: str, verbose: bool = False) -> List[str]:\n",
    "        \"\"\"When the agent makes a reaction to an observation, update their daily plan if needed.\"\"\"\n",
    "        if self.current_plan is None:\n",
    "            return self.create_daily_plan(verbose=verbose)\n",
    "        full_plan = self.current_plan\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{agent_summary_description}\"\n",
    "            +\"\\nIt is {current_time}.\"\n",
    "            +\"\\n{name} observed {observation} and had the following reaction: {reaction}.\"\n",
    "            +\"\\n{name}'s original plan for the rest of the day:\\n\"\n",
    "            +\"{original_plan}\"\n",
    "            +\"\\nIf this reaction influences the plan, respond with the updated plan at a 5-15 minute granularity. If not, return the original plan unchanged.\\n\"\n",
    "            +\"(Possibly) Updated Plan:\\n\\n\"\n",
    "            )\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=verbose)\n",
    "        current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        already_completed = []\n",
    "        original_plan = []\n",
    "        for item in full_plan:\n",
    "            split_item = item.split(' - ')\n",
    "            time_format = '%I:%M%p'\n",
    "            try:\n",
    "                time_obj = datetime.strptime(split_item[0], time_format)\n",
    "            except:\n",
    "                original_plan.append(item) # TODO: better handle errors\n",
    "            if time_obj.time() > datetime.now().time():\n",
    "                original_plan.append(item)\n",
    "            else:\n",
    "                already_completed.append(item)\n",
    "        current_plan_str = \"\\n\".join([f\"{plan}\" for plan in original_plan])\n",
    "        result = chain.run(\n",
    "            agent_summary_description=self.get_summary(), \n",
    "            current_time = current_time_str,\n",
    "            name=self.name,\n",
    "            observation=observation,\n",
    "            reaction=reaction,\n",
    "            original_plan=current_plan_str)\n",
    "        new_plan = self._parse_list(result)\n",
    "        return already_completed + new_plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c5223-889f-4799-a01b-1f4d50593d95",
   "metadata": {},
   "source": [
    "## Functions for interactions\n",
    "\n",
    "Characters are meant for interactions and actions. Let's define a few functions to parse responses to observations that can be connected to dialogue flows or virtual worlds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10834185-76b1-4d1d-a84c-edb07a31cb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_reaction(agent, observation) -> Tuple[bool, str]:\n",
    "    call_to_action_template = (\n",
    "        \"Should {agent_name} react to the observation, and if so,\"\n",
    "        +\" what would be an appropriate reaction? Respond in one line.\"\n",
    "        +' If the action is to engage in dialogue, write:\\nSAY: \"what to say\"'\n",
    "        +\"\\notherwise, write:\\nREACT: {agent_name}'s reaction (if anything).\\nEither do nothing, react, or say something but not both.\\n\\n\"\n",
    "    )\n",
    "    full_result = agent._generate_reaction(observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    agent.add_memory(f\"{agent.name} observed {observation} and reacted by {result}\")\n",
    "    if \"REACT:\" in result:\n",
    "        reaction = result.split(\"REACT:\")[-1].strip()\n",
    "        return False, reaction\n",
    "    if \"SAY:\" in result:\n",
    "        return True, result.split(\"SAY:\")[-1].strip()\n",
    "    else:\n",
    "        return False, result\n",
    "\n",
    "def generate_dialogue_response(agent, observation: str):\n",
    "    call_to_action_template = (\n",
    "        'What would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
    "    )\n",
    "    full_result = agent._generate_reaction(observation, call_to_action_template)\n",
    "    result = full_result.strip().split('\\n')[0]\n",
    "    if \"GOODBYE:\" in result:\n",
    "        farewell = result.split(\"GOODBYE:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {farewell}\")\n",
    "        return False, farewell\n",
    "    if \"SAY:\" in result:\n",
    "        response_text = result.split(\"SAY:\")[-1].strip()\n",
    "        agent.add_memory(f\"{agent.name} observed {observation} and said {response_text}\")\n",
    "        return True, response_text\n",
    "    else:\n",
    "        return False, result\n",
    "        \n",
    "def interview_agent(agent, message: str):\n",
    "    new_message = f\"Person A says {message}\"\n",
    "    return generate_dialogue_response(agent, new_message)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb84dd8-ea8f-4d9b-864a-4677a0347f49",
   "metadata": {},
   "source": [
    "## Create a Character\n",
    "\n",
    "For this example, we will create two characters named \"Tommie\" and \"Eve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608c0272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tommie = GenerativeAgent(name=\"Tommie\", \n",
    "              age=25,\n",
    "              traits=\"anxious, likes design\", # You can add more persistent traits here \n",
    "              status=\"looking for a job\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                   \"Drove across state to move to a new town but doesn't have a job yet.\"\n",
    "               ],\n",
    "               reflection_threshold = 8, # we will give this a relatively low number to show how reflection works\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c524d529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "It is not possible to provide a summary without any statements or information about Tommie's characteristics. Please provide additional context.\n"
     ]
    }
   ],
   "source": [
    "# We can see a current \"Summary\" of a character based on their own perception of self.\n",
    "# It isn't very complete right now since the character doesn't have any memories.\n",
    "print(tommie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can give the character memories directly\n",
    "tommie_memories = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "for memory in tommie_memories:\n",
    "    tommie.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6992b48b-697f-4973-9560-142ef85357d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie has memories of his childhood dog, observes his new home and noisy surroundings, notices his new neighbors have a cat, tries to rest while feeling tired from driving, and feels hungry.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-Interview with Character\n",
    "\n",
    "Before sending our character on their way, let's ask them a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I really enjoy design. It\\'s always been a passion of mine.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e2e8cc-921e-4816-82f1-66962b2c1055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Well, I\\'m actually looking for a job right now. I\\'m hoping to find something in the design field.\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you looking forward to doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2521ffc-7050-4ac3-9a18-4cccfc798c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Honestly, my biggest worry right now is finding a job in my field. It\\'s been a bit of a struggle, but I\\'m staying hopeful. How about you?\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you most worried about today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c3d46-9324-48df-a5c3-9e37fb02eb6d",
   "metadata": {},
   "source": [
    "## Create a plan for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b48b7eb-ac0e-452a-93f6-9655f8da9729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6:00am - Wake up, get dressed, and head out for a 30-minute walk to explore the new town and get some fresh air.',\n",
       " '6:30am - Return home and take a few minutes to stretch and cool down.',\n",
       " '6:45am - Shower and get dressed for the day.',\n",
       " '7:00am - Have breakfast while browsing job openings and saving any relevant ones.',\n",
       " '7:30am - Start researching companies and their values to find potential matches for job openings.',\n",
       " '8:00am - Reach out to any connections in the area to see if they know of any job opportunities or can provide any advice.',\n",
       " '8:30am - Check for any upcoming networking events or job fairs in the area and add them to the calendar if applicable.',\n",
       " '9:00am - Attend any networking events or job fairs in the area, if there are any, and make connections with potential employers or colleagues.',\n",
       " '10:00am - Begin working on creating a portfolio of design work to showcase to potential employers.',\n",
       " '10:15am - Gather any past design work and organize it by project or category.',\n",
       " '10:45am - Start selecting the best pieces and editing them to fit the portfolio.',\n",
       " '11:30am - Research design portfolio best practices and incorporate them into the portfolio design.',\n",
       " '12:00pm - Take a break for lunch and practice self-care, such as taking a short walk or doing some light stretching.',\n",
       " '12:30pm - Return to work on the portfolio, focusing on creating a cohesive and visually appealing presentation.',\n",
       " '1:30pm - Take a break to rest and recharge.',\n",
       " '2:00pm - Continue working on the portfolio, adding any finishing touches and ensuring it is up to date.',\n",
       " '3:00pm - Take a break to manage anxiety and practice self-care, such as meditation or deep breathing exercises.',\n",
       " '3:30pm - Review the progress made so far and adjust the plan for the rest of the day if necessary.',\n",
       " '4:00pm - Set specific goals and tasks for the next day, such as following up with any networking connections or submitting job applications.',\n",
       " '4:30pm - Finish up any remaining tasks for the day, such as sending out emails or making phone calls.',\n",
       " '5:00pm - Take a break to unwind before dinner, such as reading a book or engaging in a hobby.',\n",
       " '6:00pm - Have dinner and spend some time relaxing or engaging in a hobby, such as painting or listening to music.',\n",
       " '7:30pm - Wind down for the evening with some light reading or meditation.',\n",
       " '8:00pm - Get ready for bed, such as taking a hot shower or doing some light stretches.',\n",
       " \"9:00pm - Aim to get a good night's sleep for the next day by turning off electronics and getting into bed.\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tommie.create_daily_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
   "metadata": {},
   "source": [
    "## Step through the day's observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have Tommie start going through a day in the life.\n",
    "observations = [\n",
    "    \"Tommie wakes up to the sound of a noisy construction site outside his window.\",\n",
    "    \"Tommie gets out of bed and heads to the kitchen to make himself some coffee.\",\n",
    "    \"Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\",\n",
    "    \"Tommie finally finds the filters and makes himself a cup of coffee.\",\n",
    "    \"The coffee tastes bitter, and Tommie regrets not buying a better brand.\",\n",
    "    \"Tommie checks his email and sees that he has no job offers yet.\",\n",
    "    \"Tommie spends some time updating his resume and cover letter.\",\n",
    "    \"Tommie heads out to explore the city and look for job openings.\",\n",
    "    \"Tommie sees a sign for a job fair and decides to attend.\",\n",
    "    \"The line to get in is long, and Tommie has to wait for an hour.\",\n",
    "    \"Tommie meets several potential employers at the job fair but doesn't receive any offers.\",\n",
    "    \"Tommie leaves the job fair feeling disappointed.\",\n",
    "    \"Tommie stops by a local diner to grab some lunch.\",\n",
    "    \"The service is slow, and Tommie has to wait for 30 minutes to get his food.\",\n",
    "    \"Tommie overhears a conversation at the next table about a job opening.\",\n",
    "    \"Tommie asks the diners about the job opening and gets some information about the company.\",\n",
    "    \"Tommie decides to apply for the job and sends his resume and cover letter.\",\n",
    "    \"Tommie continues his search for job openings and drops off his resume at several local businesses.\",\n",
    "    \"Tommie takes a break from his job search to go for a walk in a nearby park.\",\n",
    "    \"A dog approaches and licks Tommie's feet, and he pets it for a few minutes.\",\n",
    "    \"Tommie sees a group of people playing frisbee and decides to join in.\",\n",
    "    \"Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\",\n",
    "    \"Tommie goes back to his apartment to rest for a bit.\",\n",
    "    \"A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\",\n",
    "    \"Tommie starts to feel frustrated with his job search.\",\n",
    "    \"Tommie calls his best friend to vent about his struggles.\",\n",
    "    \"Tommie's friend offers some words of encouragement and tells him to keep trying.\",\n",
    "    \"Tommie feels slightly better after talking to his friend.\",\n",
    "    \"Tommie decides to go for a jog to clear his mind.\",\n",
    "    \"Tommie jogs through the city and sees some interesting sights.\",\n",
    "    \"Tommie stops to take a picture of a street mural.\",\n",
    "    \"Tommie runs into an old friend from college who now lives in the city.\",\n",
    "    \"They catch up for a few minutes, but Tommie's friend has to leave to attend a meeting.\",\n",
    "    \"Tommie thanks his friend and feels hopeful again.\",\n",
    "    \"Tommie heads back to his apartment to rest and prepare for his upcoming interviews.\",\n",
    "    \"Tommie spends the evening rehearsing his interview pitch.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTommie wakes up to the sound of a noisy construction site outside his window.\u001b[0m Tommie groans and covers his head with a pillow to try to block out the noise.\n",
      "\u001b[32mTommie gets out of bed and heads to the kitchen to make himself some coffee.\u001b[0m Tommie makes himself some coffee.\n",
      "\u001b[32mTommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\u001b[0m Tommie sighs in frustration and continues searching through the boxes.\n",
      "\u001b[32mTommie finally finds the filters and makes himself a cup of coffee.\u001b[0m Tommie takes a sip of his coffee and feels a sense of relief.\n",
      "\u001b[32mThe coffee tastes bitter, and Tommie regrets not buying a better brand.\u001b[0m Tommie grimaces and makes a mental note to buy a better brand of coffee next time.\n",
      "\u001b[32mTommie checks his email and sees that he has no job offers yet.\u001b[0m Tommie feels disappointed but tries to stay positive and continues with his planned activities for the day.\n",
      "\u001b[32mTommie spends some time updating his resume and cover letter.\u001b[0m Tommie nods to himself, satisfied with his progress.\n",
      "\u001b[32mTommie heads out to explore the city and look for job openings.\u001b[0m Tommie feels a sense of excitement and anticipation as he sets out to explore the city and find job openings.\n",
      "\u001b[32mTommie sees a sign for a job fair and decides to attend.\u001b[0m Tommie's eyes light up with hope and he makes a mental note to attend the job fair.\n",
      "\u001b[32mThe line to get in is long, and Tommie has to wait for an hour.\u001b[0m Tommie sighs and takes out his phone to pass the time while waiting in line.\n",
      "\u001b[32mTommie meets several potential employers at the job fair but doesn't receive any offers.\u001b[0m Tommie feels discouraged but reminds himself to keep trying and not give up.\n",
      "\u001b[32mTommie leaves the job fair feeling disappointed.\u001b[0m Tommie's shoulders slump and he lets out a defeated sigh as he heads back home.\n",
      "\u001b[32mTommie stops by a local diner to grab some lunch.\u001b[0m Tommie enters the diner and looks at the menu with a grumbling stomach.\n",
      "\u001b[34mCharacter Tommie is reflecting\u001b[0m\n",
      "\u001b[32mThe service is slow, and Tommie has to wait for 30 minutes to get his food.\u001b[0m Tommie sighs and checks his phone to pass the time while waiting for his food.\n",
      "\u001b[32mTommie overhears a conversation at the next table about a job opening.\u001b[0m \"Excuse me, I couldn't help but overhear about the job opening. Do you happen to have any more information about it?\"\n",
      "\u001b[32mTommie asks the diners about the job opening and gets some information about the company.\u001b[0m \"Can you tell me more about the job opening? I'm actively searching for opportunities in the design field.\"\n",
      "\u001b[32mTommie decides to apply for the job and sends his resume and cover letter.\u001b[0m \"Thank you for the information. I will definitely apply for the job and keep my fingers crossed.\"\n",
      "\u001b[32mTommie continues his search for job openings and drops off his resume at several local businesses.\u001b[0m Tommie feels a sense of accomplishment and hope as he takes action towards finding a job.\n",
      "\u001b[32mTommie takes a break from his job search to go for a walk in a nearby park.\u001b[0m Tommie takes a deep breath and enjoys the fresh air and nature around him, feeling momentarily at peace.\n",
      "\u001b[32mA dog approaches and licks Tommie's feet, and he pets it for a few minutes.\u001b[0m Tommie smiles and enjoys the moment of interaction with the dog.\n",
      "****************************************\n",
      "\u001b[34mAfter 20 observations, Tommie's summary is:\n",
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is a determined individual who is actively searching for a job in the design field. Despite experiencing both excitement and disappointment in their job search, they remain hopeful and focused on achieving their goal. Tommie is also deeply attached to their dog, Bruno, and memories of their childhood together hold a special place in their heart. They actively network with potential employers and take action towards finding job opportunities. Despite setbacks, Tommie remains resilient and takes breaks to recharge and find moments of peace.\u001b[0m\n",
      "****************************************\n",
      "\u001b[32mTommie sees a group of people playing frisbee and decides to join in.\u001b[0m Tommie watches the group playing frisbee but decides not to join in as they are strangers.\n",
      "\u001b[32mTommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\u001b[0m Tommie rubs his nose and winces in pain before taking a break from the frisbee game.\n",
      "\u001b[32mTommie goes back to his apartment to rest for a bit.\u001b[0m Tommie lays down on the couch and closes their eyes, taking a deep breath to relax.\n",
      "\u001b[32mA raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\u001b[0m Tommie sighs and grabs a broom to clean up the mess.\n",
      "\u001b[32mTommie takes a nap but has trouble sleeping because of the noisy construction site outside his window.\u001b[0m Tommie tosses and turns in frustration, unable to sleep due to the noise outside.\n",
      "\u001b[32mTommie wakes up feeling even more tired than before.\u001b[0m Tommie groans and rubs their eyes, feeling frustrated about not getting enough rest.\n",
      "\u001b[32mTommie decides to watch some TV to relax.\u001b[0m Tommie turns on the TV and settles into the couch, feeling grateful for the distraction and chance to unwind.\n",
      "\u001b[32mThe show he's watching is a repeat, and he gets bored after a few minutes.\u001b[0m Tommie switches the channel to find something more engaging.\n",
      "\u001b[32mTommie sees a commercial for a new energy drink and decides to try it.\u001b[0m Tommie takes note of the energy drink but decides not to try it, as they are wary of the potential side effects.\n",
      "\u001b[32mThe energy drink tastes terrible, and Tommie regrets buying it.\u001b[0m Tommie throws away the energy drink and makes a mental note to avoid trying new products impulsively.\n",
      "\u001b[32mTommie starts to feel frustrated with his job search.\u001b[0m Tommie takes a deep breath and reminds themselves of their determination and resilience in their job search.\n",
      "\u001b[32mTommie calls his best friend to vent about his struggles.\u001b[0m \"Hey, just wanted to talk to you about my job search struggles and get some support.\"\n",
      "\u001b[32mTommie's friend offers some words of encouragement and tells him to keep trying.\u001b[0m \"Thank you for the support, it means a lot to me.\"\n",
      "\u001b[32mTommie feels slightly better after talking to his friend.\u001b[0m \"Thank you for your kind words. It really helps to have your support.\"\n",
      "\u001b[32mTommie decides to go for a jog to clear his mind.\u001b[0m Tommie puts on his running shoes and heads out for a jog to clear his mind.\n",
      "\u001b[32mTommie jogs through the city and sees some interesting sights.\u001b[0m Tommie enjoys the sights and feels energized by the jog.\n",
      "\u001b[32mTommie stops to take a picture of a street mural.\u001b[0m Tommie smiles and admires the street mural before continuing their jog.\n",
      "\u001b[32mTommie runs into an old friend from college who now lives in the city.\u001b[0m \"Hey, it's great to see you! How have you been?\"\n",
      "\u001b[32mThey catch up for a few minutes, but Tommie's friend has to leave to attend a meeting.\u001b[0m \"It was great running into you! Let's catch up again soon.\"\n",
      "\u001b[32mTommie thanks his friend and feels hopeful again.\u001b[0m \"Thanks for the reminder that there are still good things happening in my life.\"\n",
      "****************************************\n",
      "\u001b[34mAfter 40 observations, Tommie's summary is:\n",
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is a determined and hopeful individual who holds a special place in their heart for their dog, Bruno. They are actively searching for a job in the design field and experiencing both excitement and disappointment in their job search. Despite facing challenges, Tommie remains determined to find a job and actively networks with potential employers and connections. They react positively to encouragement and take action towards finding a job. However, Tommie also experiences moments of disappointment and defeat.\u001b[0m\n",
      "****************************************\n",
      "\u001b[32mTommie heads back to his apartment to rest and prepare for his upcoming interviews.\u001b[0m Tommie takes a deep breath and mentally prepares for his upcoming interviews.\n",
      "\u001b[34mCharacter Tommie is reflecting\u001b[0m\n",
      "\u001b[32mTommie spends the evening rehearsing his interview pitch.\u001b[0m Tommie nods their head in determination and continues to rehearse their interview pitch.\n"
     ]
    }
   ],
   "source": [
    "# Let's send Tommie on their way. We'll check in on their summary every few observations to watch it evolve\n",
    "for i, observation in enumerate(observations):\n",
    "    _, reaction = generate_reaction(tommie, observation)\n",
    "    print(colored(observation, \"green\"), reaction)\n",
    "    if ((i+1) % 20) == 0:\n",
    "        print('*'*40)\n",
    "        print(colored(f\"After {i+1} observations, Tommie's summary is:\\n{tommie.get_summary(force_refresh=True)}\", \"blue\"))\n",
    "        print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62a275-7290-43ca-aa0f-504f3a706d09",
   "metadata": {},
   "source": [
    "## Interview after the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6336ab5d-3074-4831-951f-c9e2cba5dfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hey, it\\'s been a bit of a mixed day, but overall it\\'s been okay. I went for a jog and saw some cool sights, which was nice. How about you?\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"Tell me about how your day has been going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809ac906-69b7-4326-99ec-af638d32bb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I actually don\\'t drink coffee, but I love the smell of it. How about you?\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How do you feel about coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f733a431-19ea-421a-9101-ae2593a8c626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I actually don\\'t drink coffee, but I love the smell of it. How about you?\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are your thoughts on coffee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9261428-778a-4c0b-b725-bc9e91b71391",
   "metadata": {},
   "source": [
    "## Adding Multiple Characters\n",
    "\n",
    "Let's add a second character to have a conversation with Tommie. Feel free to configure different traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8bbe18-a021-419c-bf1f-23d34732cd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eve = GenerativeAgent(name=\"Eve\", \n",
    "              age=34, \n",
    "              traits=\"curious, helpful\", # You can add more persistent traits here \n",
    "              status=\"N/A\", # When connected to a virtual world, we can have the characters update their status\n",
    "              memory_retriever=create_new_memory_retriever(),\n",
    "              llm=LLM,\n",
    "              daily_summaries = [\n",
    "                  (\"Eve started her new job as a career counselor last week and received her first assignment, a client named Tommie.\")\n",
    "              ],\n",
    "                reflection_threshold = 5,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e2745f5-e0da-4abd-98b4-830802ce6698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "eve_memories = [\n",
    "    \"Eve overhears her colleague say something about a new client being hard to work with\",\n",
    "    \"Eve wakes up and hear's the alarm\",\n",
    "    \"Eve eats a boal of porridge\",\n",
    "    \"Eve helps a coworker on a task\",\n",
    "    \"Eve plays tennis with her friend Xu before going to work\",\n",
    "    \"Eve overhears her colleague say something about Tommie being hard to work with\",\n",
    "    \n",
    "]\n",
    "for memory in eve_memories:\n",
    "    eve.add_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4726e3-4bb1-47da-8fd9-f317a036fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is a helpful and active person who is attentive to the people around her and enjoys sports.\n"
     ]
    }
   ],
   "source": [
    "print(eve.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837524e9-7f7e-4e9f-b610-f454062f5915",
   "metadata": {},
   "source": [
    "## Pre-conversation interviews\n",
    "\n",
    "\n",
    "Let's \"Interview\" Eve before she speaks with Tommie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cda916d-800c-47bc-a7f9-6a2f19187472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m feeling pretty good so far, thanks for asking! How about you, Person A?\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How are you feeling about today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "448ae644-0a66-4eb2-a03a-319f36948b37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I don\\'t know much about Tommie, but I overheard someone saying he\\'s hard to work with. Have you had any experiences working with him?\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you know about Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "493fc5b8-8730-4ef8-9820-0f1769ce1691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"That\\'s interesting to hear. What kind of job is Tommie looking for?\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"Tommie is looking to find a job. What are are some things you'd like to ask him?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b46452a-6c54-4db2-9d87-18597f70fec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sure, I\\'d be happy to ask him questions and learn more about his job search. What kind of experience or skills is he looking to bring to a job?\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"You'll have to ask him. He may be a bit shy, so I'd appreciate it if you keep the conversation go and ask as many questions as possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780655-1d73-4fcb-a78d-79fd46a20636",
   "metadata": {},
   "source": [
    "## Dialogue between Generative Agents\n",
    "\n",
    "Generative agents are much more complex when they interact with a virtual environment or with each other. Below, we run a simple conversation between Tommie and Eve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "042ea271-4bf1-4247-9082-239a6fea43b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conversation(agents, initial_observation: str, max_turns:int = 25, reflection_frequency: Optional[int] = 5):\n",
    "    _, observation = generate_reaction(agents[1], initial_observation)\n",
    "    print(f\"{agents[1].name}: {observation}\")\n",
    "    turns = 0\n",
    "    while True:\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, reaction = generate_dialogue_response(agent, observation)\n",
    "            print(f\"{agent.name}: {reaction}\")\n",
    "            observation = f\"{agent.name} said {reaction}\"\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True   \n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5462b14-218e-4d85-b035-df57ea8e0f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eve: \"Sure, I'd be happy to share my story and offer any advice that might be helpful.\"\n",
      "Tommie: \"Thank you for giving me the chance to share. It means a lot to me to have someone to talk to about my job search.\"\n",
      "Eve: \"Of course, Tommie. I'm glad that I could be here to listen and offer any help that I can. Can you tell me more about the type of job you're looking for?\"\n",
      "Tommie: \"Thank you, Eve. I'm really interested in finding a job in the design field. Specifically, I'm looking for opportunities in graphic design or web design. I have experience with both and I'm excited about the creative possibilities in these fields.\"\n",
      "Eve: \"That's great, Tommie! It sounds like you have a lot of valuable skills to offer in the design field. Have you been actively searching for job opportunities in those areas?\"\n",
      "Tommie: \"Yes, I have been actively searching and applying for jobs in those areas. It's been a bit of a challenge, but I'm staying hopeful and determined. Thank you for your support, Eve.\"\n",
      "Eve: \"That's great to hear, Tommie. I'm glad you're staying positive and determined in your job search. I'll keep my eyes open for any opportunities that might be a good fit for you. Is there anything else I can do to help in the meantime?\"\n",
      "Tommie: \"Thank you so much, Eve. Your support means a lot to me. If you come across any job opportunities or connections, please let me know. I'll continue to keep you updated on my job search progress.\"\n",
      "Eve: \"I'll definitely keep you in mind, Tommie. And please do keep me updated on your progress. I'm rooting for you! Is there anything specific you're looking for in a job or company culture?\"\n",
      "Tommie: \"Thank you, Eve. In terms of company culture, I'm looking for a place that values creativity and collaboration. I enjoy working in a team environment and bouncing ideas off of others. I'm also interested in a company that values work-life balance and offers opportunities for growth and learning. Thank you again for your support and for keeping me in mind for any opportunities.\"\n",
      "Eve: \"Those are all great qualities to look for in a company, Tommie. I'll definitely keep those in mind as I come across job opportunities. And please do keep me updated on your progress. I'm here to support you in your job search. Good luck!\"\n",
      "Tommie: \"Thank you so much, Eve. I really appreciate your support and willingness to help. I'll definitely keep you updated on my progress and any new opportunities I come across. Thanks again, and have a great day!\"\n",
      "Eve: \"You're welcome, Tommie. I'm happy to help in any way I can. Good luck with your job search and keep me updated. Have a great day!\"\n"
     ]
    }
   ],
   "source": [
    "agents = [tommie, eve]\n",
    "run_conversation(agents, \"Hi, Eve. Thanks for agreeing to share your story with me and give me advice. Maybe we can start with how you got into the industry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28fe80-03dc-4399-961d-6e9ee1980216",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's interview our agents after their conversation\n",
    "\n",
    "Since the generative agents retain their memories from the day, we can ask them about their plans, conversations, and other memoreis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4d252f3-fcc1-474c-846e-a7605a6b4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design\n",
      "Tommie is a determined and hopeful job seeker in the design field who values the support of friends and loved ones. They experience a mix of excitement and disappointment in their job search, but remain persistent and take breaks to find peace in nature. Tommie also holds their childhood memories close, especially those involving their beloved dog, Bruno.\n",
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is a supportive and helpful person who is willing to listen and offer assistance to those in need. She is empathetic and asks thoughtful questions to better understand the needs of others. She is also interested in learning about and supporting career growth and development. Additionally, she is friendly and approachable in social situations.\n"
     ]
    }
   ],
   "source": [
    "# We can see how the agents have \n",
    "print(tommie.get_summary(force_refresh=True))\n",
    "\n",
    "# We can see a current \"Summary\" of a character based on their own perception of self\n",
    "print(eve.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71762558-8fb6-44d7-8483-f5b47fb2a862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"It was really helpful, actually. Eve offered to keep an eye out for any job opportunities and she asked about the type of job and company culture I\\'m looking for. It\\'s nice to have someone in my corner rooting for me. Thanks for asking, Person A.\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How was your conversation with Eve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "085af3d8-ac21-41ea-8f8b-055c56976a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"It was really nice to talk to Tommie and learn more about his job search. He\\'s looking for opportunities in graphic design or web design, and I promised to keep him in mind for any job opportunities that come my way. He\\'s a really talented and motivated individual, and I\\'m excited to see where his career takes him.\"'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How was your conversation with Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b439f3c-7849-4432-a697-2bcc85b89dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCharacter Eve is reflecting\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"I feel like I covered most of the things I wanted to ask and offer, but if there\\'s anything else you want to share or ask me, please don\\'t hesitate to reach out. I\\'m here to support you in any way I can. Good luck with your job search, Tommie!\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you wish you would have said to Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb7532-e38f-4278-8dc4-5b95df6c8a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
