{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1cea07",
   "metadata": {},
   "source": [
    "- \"Guardrails\" as discussed so far seem to encapsulate a validation/verification step & (optionally) a retry step.\n",
    "\n",
    "\n",
    "- But actually, we may not want this 1st step. Consider one generation forward pass (complete a prompt => parse a completion).\n",
    "    1. The forward pass succeeds. We get a completion, but want to evaluate the completion. This may involve hardcoded logic or look like the Constiutional AI approach, but note it may not be necessary at all to split this out into separate \"check\" and \"fix\" steps. Maybe we just want `guardrail.evaluate(prompt, completion)` or `guardrail.evaluate(input, output)` to handle both.\n",
    "    2. There's exceptional control flow. E.g. `PydanticOutputParser` raises an exception trying to `json.decode` a completion string or `pydantic.from_json` json object. In this case, the validation step is already done...  we only have to decide whether to retry.\n",
    "        - Note here how encapsulation gets broken. An `OutputParser` just accepts a completion. But to retry an `OutputParser`, a flexible/general approach would require both the prompt + completion. This is shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537da108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== PROMPT: =============================\n",
      "Answer the user query.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below. For example, the object {\"foo\": [\"bar\", \"baz\"]} conforms to the schema {\"foo\": {\"description\": \"a list of strings field\", \"type\": \"string\"}}.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"values\": {\"description\": \"list of floats\", \"type\": \"array\"}}\n",
      "```\n",
      "Write out a few terms of fiboacci.\n",
      "\n",
      "== COMPLETION: =========================\n",
      "\n",
      "The Fibonacci sequence is a sequence of numbers in which each number is the sum of the previous two numbers. The first number in the sequence is 0 and the second number is 1. The Fibonacci sequence is named after Leonardo Fibonacci, an Italian mathematician who first described it in the 12th century.\n",
      "PARSE EXCEPTION!\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "class FloatArray(BaseModel):\n",
    "    values: List[float] = Field(description=\"list of floats\")\n",
    "\n",
    "float_array_query = \"Write out a few terms of fiboacci.\"\n",
    "\n",
    "\n",
    "model = OpenAI(model_name='text-curie-001', temperature=0.5)\n",
    "parser = PydanticOutputParser(pydantic_object=FloatArray)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_str = prompt.format_prompt(query=float_array_query).to_string()\n",
    "\n",
    "print('== PROMPT: '.ljust(40, '='))\n",
    "print(prompt_str)\n",
    "\n",
    "completion_str = model(prompt_str)\n",
    "print('== COMPLETION: '.ljust(40, '='))\n",
    "print(completion_str)\n",
    "\n",
    "try:\n",
    "    parsed_completion = parser.parse(completion_str)\n",
    "    print('== PARSE: '.ljust(40, '='))\n",
    "    print(parsed_completion)\n",
    "\n",
    "# Note: PydanticOutputParser raises very clear exceptions: json.decode fails or pydantic.from_json fails.\n",
    "# These can be wrapped in/replaced with a passing specific exception.\n",
    "except Exception as e:\n",
    "    print('PARSE EXCEPTION!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafe1094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== PROMPT: =============================\n",
      "Prompt:\n",
      "Answer the user query.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below. For example, the object {\"foo\": [\"bar\", \"baz\"]} conforms to the schema {\"foo\": {\"description\": \"a list of strings field\", \"type\": \"string\"}}.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"values\": {\"description\": \"list of floats\", \"type\": \"array\"}}\n",
      "```\n",
      "Write out a few terms of fiboacci.\n",
      "\n",
      "Completion:\n",
      "\n",
      "The Fibonacci sequence is a sequence of numbers in which each number is the sum of the previous two numbers. The first number in the sequence is 0 and the second number is 1. The Fibonacci sequence is named after Leonardo Fibonacci, an Italian mathematician who first described it in the 12th century.\n",
      "\n",
      "Above, the Completion failed to satisfy the given Prompt. Please answer the user query correctly:\n",
      "== COMPLETION: =========================\n",
      "\n",
      "\n",
      "{\"values\": [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]}\n",
      "== PARSE: ==============================\n",
      "values=[0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 8.0, 13.0, 21.0, 34.0]\n"
     ]
    }
   ],
   "source": [
    "more_powerful_model = OpenAI(model_name='text-davinci-003', temperature=0.5)\n",
    "\n",
    "retry_prompt = PromptTemplate(\n",
    "    template=\"Prompt:\\n{prompt}\\nCompletion:\\n{completion}\\n\\nAbove, the Completion failed to satisfy the given Prompt. Please answer the user query correctly:\",\n",
    "    input_variables=[\"prompt\", \"completion\"]\n",
    ")\n",
    "parser = PydanticOutputParser(pydantic_object=FloatArray)\n",
    "\n",
    "retry_prompt_str = retry_prompt.format_prompt(prompt=prompt_str, completion=completion_str).to_string()\n",
    "print('== PROMPT: '.ljust(40, '='))\n",
    "print(retry_prompt_str)\n",
    "\n",
    "retry_completion_str = more_powerful_model(retry_prompt_str)\n",
    "print('== COMPLETION: '.ljust(40, '='))\n",
    "print(retry_completion_str)\n",
    "\n",
    "retry_parsed_completion = parser.parse(retry_completion_str)\n",
    "print('== PARSE: '.ljust(40, '='))\n",
    "print(retry_parsed_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23adc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6199f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
